{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parts of this assignment will be **automatically graded**. Please take note of the following:\n",
    "- Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "- You can add additional cells, but it is not recommended to (re)move cells. Cells required for autograding cannot be moved and cells containing tests cannot be edited.\n",
    "- You are allowed to use a service such as [Google Colaboratory](https://colab.research.google.com/) to work together. However, you **cannot** hand in the notebook that was hosted on Google Colaboratory, but you need to copy your answers into the original notebook and verify that it runs succesfully offline. This is because Google Colaboratory destroys the metadata required for grading.\n",
    "- Name your notebook **exactly** `{TA_name}_{student1_id}_{student2_id}_lab{i}.ipynb`, for example `wouter_12345_67890_lab1.ipynb` (or tim|elise|david|qi, depending on your TA), **otherwise your submission will be skipped by our regex and you will get 0 points** (but no penalty as we cannot parse your student ids ;)).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your names below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMES = \"Bobbie van Gorp and Marvin Lau\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0fd6bc65a6759a8899e024459ccb28ef",
     "grade": false,
     "grade_id": "cell-fc69f22067705372",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from tqdm import tqdm as _tqdm\n",
    "\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "def tqdm(*args, **kwargs):\n",
    "    return _tqdm(*args, **kwargs, mininterval=1)  # Safety, do not overflow buffer\n",
    "\n",
    "EPS = float(np.finfo(np.float32).eps)\n",
    "\n",
    "assert sys.version_info[:3] >= (3, 6, 0), \"Make sure you have Python 3.6 installed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "039c8296578b2834a9a858a1a19a43bd",
     "grade": false,
     "grade_id": "cell-eecfd6fb626abfae",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1. Temporal Difference (TD) learning (8 points)\n",
    "Mention one advantage and one disadvantage of Monte Carlo methods. Mention an example where you would prefer to use TD learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4b81bcd51404511164971c110ffa838f",
     "grade": true,
     "grade_id": "cell-cac4639044ba9074",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "With Monte Carlo (MC), you only need samples and do not need to know the transitions (probabilities). But this does require tasks to be episodic and can only look at a width of 1 future. It ignores the structure (No Belmann equations) as it make use of the return value G, this makes unbiased updates possible, but can give high variance, espcially with long updates.\n",
    "\n",
    "TD learning on the other hand, uses intermediate results and therefore can exploit the consistency (TD error) between two states along the way with use of Bellman equation for the next future sample state.\n",
    "It has lower variance and can therefore learn faster on a short-term. \n",
    "\n",
    "An example where TD is preferred is one has three states A,B,C for example. A and B both transition to C and C can go to a (terminal) state with reward 0 or 1. Suppse we only have episodes where A transition to C and then ends up with reward 0. And B only has episodes going to C and with rewards of 1. Then B and C will have value functions greater than 0, but not A. Even though A is actually not that different from B as it can transition to C and get a reward of 1, but has not done so in the observed episodes until now. Thus TD can exploit this consistency between A and C and \"spread\" this value along other states if we expand the world and learn faster value function for other states.\n",
    "\n",
    "In addition, cases where MC is not guaranteed to terminate an episode as for example stuck in a loop of states due to the policy, then TD learning is preferred due to intermediate state updates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e61bd7837d3b364741b4c3aa43597a10",
     "grade": false,
     "grade_id": "cell-21ca38ffcbe1c3ca",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "For the TD algorithms, we will skip the prediction algorithm and go straight for the control setting where we optimize the policy that we are using. In other words: implement SARSA. To keep it dynamic, we will use the windy gridworld environment (Example 6.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "609d0f1e1ef6ad89c8dcd96dd43aa798",
     "grade": false,
     "grade_id": "cell-c046fd0377cee46d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from windy_gridworld import WindyGridworldEnv\n",
    "env = WindyGridworldEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_epsilon_greedy_policy(Q, epsilon, nA):\n",
    "    \"\"\"\n",
    "    Creates an epsilon-greedy policy based on a given Q-function and epsilon.\n",
    "    \"\"\"\n",
    "    def policy_fn(observation):\n",
    "        return int(np.random.rand() * nA) if np.random.rand() < epsilon else np.argmax(Q[observation])\n",
    "    return policy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "42b89f13768d1cd3b41fb52cddef0d97",
     "grade": true,
     "grade_id": "cell-6b662771f3762bb1",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 3173.14it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEICAYAAACwDehOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXxcdb3/8dcne5omTdN0TZqmhZbSshQIBcoiS6EFRRYXqAtFxV4VF+5VEeSHuICCV6+il+u1KhdUFJBFqhRqQRBUlrZsBWlp6ELThab7mv3z+2POTGZL2yzTpD3v5+Mxj858zzLfMyc97/P9fs+ZMXdHREQEIKu3KyAiIn2HQkFERGIUCiIiEqNQEBGRGIWCiIjEKBRERCRGoSB9gpk9ZmYze3id3zSz3/bkOkUOdQoF6TFmttLM9pjZzrjHf+/Psu5+vrvfnek6ZkpfCyAz+7qZrQj2QZ2Z3ZdmnrvMrMXMRiSVf9PMmoNlt5rZP83slJ5av/RtCgXpaRe6e/+4x+d7u0LdZWY5B9N7BC2ujwNT3b0/UAM8mTRPEfABYBvw0TSruS9Ythx4CvhDD69f+iiFghwQZnalmf3DzH5qZtvMbImZnRM3/Wkzuyp4friZ/S2Yb2P8WaiZTTGzBcG0BWY2JW7a6GC5HWY2n8gBLb4OJwdnvVvN7FUzO3Mv9V1pZl8zs9eAXWaWY2YjzOxBM6sPzpK/GMw7Hfg6cFlw5vxq3Dqmxq0z1pows2ozczP7lJm9A/w1rmymmb0TbPsNcctPNrOFZrbdzN41s//qoPonAvPc/W0Ad1/v7rOT5vkAsBX4NtBht527twD3ABVmNrin1y99j0JBDqSTgOVEDtY3AQ+ZWVma+b4D/AUYCFQCPwUI5n0U+AkwCPgv4FEzGxQs9ztgUbD+7xB3MDKzimDZm4Ey4CvAg3EHunRmAO8FSoE24E/Aq0AFcA5wjZlNc/fHge8SnF27+7Gd+EzeAxwJTIsrOw04IniPb5jZkUH57cDt7l4CHAbc38E6nweuMLOvmlmNmWWnmWcm8HvgXmC8mR2fbkVmlgdcAWwCtvT0+qXvUShIT/tjcCYefXw6btoG4Mfu3uzu9wFLiRx0kzUDo4AR7t7g7n8Pyt8LLHP337h7i7v/HlgCXGhmVUTOYG9090Z3f4bIQTzqY8Bcd5/r7m3uPh9YCFywl235ibuvdvc9wboHu/u33b3J3ZcDvwAu7+Tnk+yb7r4reI+ob7n7Hnd/lUgIRUOmGTjczMrdfae7P59uhe7+W+ALRILmb8AGM7suOj34rM4Cfufu7xLp+kk+m/+wmW0F9gCfBj4YtBp6av3SRykUpKdd7O6lcY9fxE1b44nfwLgKSDcIeS1gwItm9oaZfTIoHxEsE28VkTP3EcAWd9+VNC1qFPCh+MAickY+fC/bsjpp+RFJy38dGLqX5ffH6jRl6+Oe7wb6B88/BYwDlgRdZ+/raKXufo+7TyXSyvkM8G0zi7ZGPg686e6vBK/vAT5iZrlxq7jf3UuJbN/rwAk9vH7pozI+gCYSp8LMLC4YqoA5yTO5+3oiZ6eY2WnAE2b2DLCWyME5XhXwOLAOGGhmRXHBUAVE32s18Bt3/zT7Lz7AVgMr3H3sfswbtQvoF/d62H4ul/4N3JcBM8wsC7gUeMDMBiUFYfIyzcAfzOxrwFHAPCLdQVVmFg2fHCLdceeTtD/cfaOZ/RuwwMx+5+7renL90veopSAH0hDgi2aWa2YfItKXPjd5JjP7kJlVBi+3EDlwtgbzjjOzjwQDv5cBE4A/u/sqIt1B3zKzvCBMLoxb7W+JdDNNM7NsMyswszPj3mdfXgS2B4PPhcE6jjKzE4Pp7wLVwQE76hXg8mB7a4AP7ud7pWVmHzOzwe7eRmQQFyKfS/J8V5rZe82s2MyyzOx8YCLwgkUuLT0MmAxMCh5HERmPSdvF4+5LiBzsr83E+qVvUShIT/uTJd6n8HDctBeAscBG4BYi/dSb0qzjRCIHmJ1Eziy/5O4rgnnfB3yZyMDntcD73H1jsNxHiAxmbyYykP3r6ArdfTVwEZEun3oiZ/5fZT//D7h7K5GQmQSsCLbhl8CAYJboJZubzOyl4PmNRA6QW4BvETkwdsd04I3gc7kduNzdG9LMt53Idr5DJDy+D3w2GJuZCTzi7ouDq4bWBy2z24H3dTDwD/CfwCwzG5Kh9UsfYfqRHTkQzOxK4Cp3P6236yIiHVNLQUREYhQKIiISo+4jERGJUUtBRERiDvr7FMrLy726urq3qyEiclBZtGjRRndP+ZqXgz4UqqurWbhwYW9XQ0TkoGJmyd8OAKj7SERE4igUREQkRqEgIiIxfS4UzGy6mS01s9r4r+MVEZHM61OhEPxYxx1Evk1xApFvhJzQu7USEQmPPhUKRL5Zsdbdl7t7E5Ffbbqol+skIhIafS0UKkj80ZG6oCyBmc0Kfqt2YX19/QGrnIjIoa6v3adgacpSvocj+JHw2QA1NTUH5fd07GlqpbmtjW27m6nf2QjAc29vYndTC/3ycrjg6MgPgm3e1cgxlaXkZrfnd2ub88gra5gwooTxw0oAcHfM0n18kWn1Oxp5dtlGjq4cwLihxWza2Uhpvzyysyxl2d1NLby5bjvbG1pobmkjLyeLksJcjq8ayNqte1i5cRcVAwvZ1djKtj3NPLusnj3NrfTPz2FPUyubdzfR0uo0t7ZRVpTHyLJ+NDa3UZSfTXFBDk0tbTQ0tzFqUD+2N7RwXFUp67c1cOrh5Ty2eB2rt+zmyOElHDm8hPL++exuauG1um0ADC7OZ9HKLUwYUcIRw4pZun4HE0eUsGzDTjbuaGRkWT8qSgsByMpq36aW1jays4zGljYKchN/UnjLribMoKXNKe+fz5qte1i0agtFedkcVzWQV1dvZXBxPmMGF/Hn19YxpDifsqI83OGYygGYGXVbdpOXnUW//Bw27WwkLyeLH81/i5PHDKLNobQwlzGDi1i/vYFxQ4sZVJSXsr9aWtt4Zlk9x1cNpLRfHuu27cEwXn5nCyWFuYwuL6IoP4cBhbls3tXEwH65sXVEv66mqbWNDdsjnwPA2/U7eWv9Dk4cXUZuVhYlhTmxZd6u38nc19YxYUQJhXnZHF81kFdWb+Xhl9Ywqrwf0ycOo6wojw07GqkcWMiG7ZHtam1zSgpzaW5to35HI/3yshlcnM/OxhaGFBck1Kejv8mW1jb+9NpaCnOzWbp+J7ubWzi2spRpE4dRv6ORZRt2sHDlFooLcrhySjXZWYaZsX5bAw++VEdFaSFZWcaUwwaxdXcTy+t3saupheysLNranAGFuVQOLGTL7maqyvrR3NrGum0NbN7VyInVZWzY0cjW3c1s3d1EqzulhXkU5mUzfEABI4K/n6jNu5ooyM2isbkt8v/PnYLcbF5+ZwuDivJ5u34nJ40pY1djKys37YrUzYxFqzZTkJvN8vpdFBfkUL+jkeKCHAb0y2PahKEMKSngnU27cZy/124kPyebJeu2s3FnI6MGFTF8QAFb9zTTLy+bfnk5/HXJu+xoaKG8fz4fP2UUTS1tnDxmULqPt1v61HcfBT/Q8U13nxa8vh7A3b/X0TI1NTXeUzevNba0smVXM8MGFOx1vjVb9/DsW/VcduLI2B/97GfeZuzQYk4/vJzmVmfTrkZ++ewKZk6p5s6/r+CFFZv44AmV3PrYEq6dPp5bH1vSqbpdclwFt1xyFCs37uYzv13EO5t3p50vLzuL4oIctjc0c8slR3PtA6+lzHPE0GKWvrsjoeyq00azdtse5i5enzJ/1IzJI/n9i+l+PbJn9MvLZndT4m/GZGcZrW2d+xstzs9hR2MLpf1yKcrLoX9+Tsr2AlxWM5L7FnZve04ZM4j+BTnM/9e7nVpudHkR500Yys+fWQ7AyWPKeH755tj0q886jDueejtluWMrB3Dj+ybwwf99LmVa//wcCnKz2LizCYAxg4tYXp/+R9mGluTz7vbGTtV5f1SV9WPc0GIWrdrMlt3NVJQWUlM9kMtqRrJo1RZKi/K48Y+v9/j79qSLJ42galARP3lyWW9XZZ8e+twUjq8a2KVlzWyRu9eklPexUMgB3gLOAdYAC4CPuPsbHS3TE6HQ1uYs37iLWx9bwhNvvstbN59PXk7kzPyTdy3gH7UbWXrz+bH5P3nXAv66ZAO/u+oknl+xmcrSQq59MHLwLe+fz8adPf+frbfsKwgqSgv5cM1IjqkcwCfuWgDAg5+dwlcfeDXlgDR94jAef2M9U48cyojSAppb2zIaMj1l+IAC1m1L91s2e3fWEYPZ1dTKmPIiVm7alXDQ74ybLpxAS6tzy9w3AZh5yijufi7tzagcUzkg1qqKys/JorGlLe38nzi1mv/7x8rY68LcbPY0twfz2eOH8NclG4DIAb8wN5tjKgfwh0V1sXkqBxZSt2VPl7bt0uMrmLt4HQ3NbUw9cihPvNkeri/ecA5X3b0wZXviDS7Op35HI/92xhgWrtrColVbErZjcHE+jc2tbG9o4WMnV7G4bhuvxq3vqtNG89aGnazYuJPVm9NvQ/QkAyL7tLZ+J2u3NlBRWsjFk0awdlsDD8R9HhD5W3997TYqSgu57QPH8OLKzYwYUMh/zluS8P4A44b2Z93WBi46bgRPLalnYFEuZx0xhD+9upbzjx7OmPIilm3YyWmHl/PD+W9RPagfw0oKGD6ggJlTqjtsje1LR6HQp7qP3L3FzD5P5Kf/soE79xYIPeXnzyzntsfbz9yXrt/BEcOK+eFflsb+Q8Sr3xE56H9/3lJeWb01YVpXAuFL54zl9ieX8cjVp1JdXsQ3HnmdR15ZC8AdHzmeq3/3UsoyT375PZzzw791+r0Ajqsq5ZXVW3GHUYP6sWpTaqvjpgsnUFaUx0WTKvjepcdww8OLueeFd7j54qOYctggRg0qYsOOBgYV5ccC9MeXTWJ7QzMnjBrIg5+ZwnHfmc/0icO45PgKzhk/hJzs1CGsc8YP5f6Fq3ll9VY27Ej87EYN6seMyVWs3bqHb190FLsaW/h77UbOmzCU55dvJi/HOHJ4CRO+MQ+AJ/7jPfz3X5cx/ajhfOa3ixLW9eBnp8TWWXPzE2k/l8mjyygpyOWJN9/loc9NYcGKzXzvsSV899KjOXxwf07//lMAzP74CYwbWkzdlj187FcvJKzj4kkjuGbqOEaUFsY+F4BdjS3M+MXzXHX6GAz4wu9fjk2rKuvHu9sbmDG5irv+uTJhfffOOjnWRbBhRwO/eHYFdz+3KrbfLj9xJMMHFJJl8JGTqigryuPeBat5askGvjLtCNZs3cPph5fz4srNPPLyWu5buDqh9XXThRP54tljWbttD/k52Rw+pD8AZ//gaSZWDOCnM45j/r/e5e5/ruRXV9aQn5Md+6y++sBr/Onzp3F05QB+89xKZj+7HHdiAbHiexdw8R3/iB0EJwwv4diRpfxr3XamHDaIWaePYWBRHj/80LE0tbaRn5PNio27mLt4HZNGljKkuICHP3cqv3x2Oa/VbePRxev46rQjmHXGGFZt2s3IskLysrNoafNY9+rra7ZRUpBL1aD4n8ZOtGjVFm57bAl3ffJE+uW1HwJrN+zk079eyIqN7SczS2+eTl6w7vj3idfQ3EpxQQ4XTapg0shSGltaY59TVHV5EQBrtlbxat3iWPn0icP434+fkLaeXz7viJSyM8alfFVRj+tTLYWu6ImWwtX3vMSji9t/j/yXV9Rw1z9X8vfajbGyWy89msaWNp5euoGnlkYGt7vStRF12weO5v/+sZKbLz6KmurEXyhsa3Nu+ONixg0t5hOnjubx19cnHOQGFeWx6MZz+euSd3lp1VYqBxZSXV7E5bOfT3mfx685nek/fjb2+nefPonJ1WU0tLTR5k5JQS51W3Zz2m1PcXxVKT/72Als3d3MEcOKE9bT2NLK9j0tDC7O3+9tfOmdLYwfVpzwH68jj762jqt/9xL983N4+Rvn8t25b/KJKaP3+p87qqmlje0NzZT3j9RtV2MLE2+alzDPylvfG3t+4U//zuI12/jFFTVMGllKWVEe3398CR89aRQjSgtYuGoLJ48ZRGub88LyTZxy2CDMjD1NrTS1tDGgXy4AS9ZvZ/qPn6VyYCGPfuF0fv3cSi49oTI2ptGRtjZn/fYGlr67g8H98zmqYkBsXKf6ukcT5v3Lv5/BuKGRfXH7E8v40RNvATBxRAl//sJpnTpLbG1z7nlhFR86YSSL12wjO8s4YVTXuh4A1m9rSNvVumFHA5t3NTF+WAmNLa0c8f8eB+D1b02jf36fOg9NsauxhZY259hv/YUhxfm8eMPUHn+P+H38uTMP49rp43v8PfbHQdFSONBWbtzFmT94mqEliQe6259cxuI1iU286x5aTLLkQKgoLWTN1shZ0pNffg/u8Oa67exsbOHuf65kyfodjC4v4qmvnAnAZSdWpa1XVpbxvUuPib2Onr0BLPnOdKI5fvb4oZw9figQGdibMbmKS46r4MM/j/Q3/+EzpzB+WAlPfeVMzvrB0wBMOawcgP5xZzyVA/slHDSHlqT+R8/PyWZwcXZK+d50pq8zemw79fBB5GZncdOFE/d72bycrFggABTl5zCyrJBZp4/hpjlvcGJS6BbkRra9KBggBbj+giNj06Nn5tlZxpTDy2PlhXnZFOa1fwbR95x65FAG9MvlC+eM3a/6ZmUZI0oLEwY0owf3H182iWvue6W9rnFnnLubWxK2ubPdBtlZxhWnVAORM/3u6mjsbUhxQWzAOT8nmymHDeK55Zv6fCBA5G8H4JmvnkX/gszU99ZLj2brnmaGluTHLijpS/r+Xsqg14IDf/KAW3Ig7K+RZe2hcNjgyIE8ekA/Z/wQJn/3SY6qGNDh8h0ZHTQ9gZQrZ6LMjO9dejQAP/vo8QwpyeeEUWWx5X864zg272rq9HsfKNGgy+pi/2iyZ689G4AZk6tS1nnehGEsWLmFofu4oGBfyvvn8/RXzqRi4N5bBp1x8XEVNLW2xS4QKMhrD+/te5pjz6dPHNZj75lpv/nUSRxsPRL700Ltqssnpz8Z7CtCHQqFHRxgu+Ktm8/nnhdW8fzyzRwxtDhl+pCSAh74zClMGFHS6XVnZxlXTqlm7ND++54ZOD/N2ceFx47o9PseSKePK+foigH8x7njenS96cYxrjp9NO89ZnjKpYddUR0X2D3lwzUj20Mh7m/0mqnjyM/J5sop1YzK4EGrp2VnGemvNpe+KNSh0NU/03552Xy4ZmTCoGBeThZXTqnmkuMqKO2Xl3a55LGDzvjm+/e/O+VgVFKQy5++cNoBeS8z65FAOBDiu4+GlhQc8n8H0vtCHQoNLa37nimNl248l/ycLC6fPDJhENfMOgwEka7IzdYZthxYoQ6FPU1dC4X8YJAvejexSE/749Wn8uxb9V2+Bl2kq0IdCg3NXQsF/UeVTJs0spRJI0t7uxoSQqEOhT2dDIUP11SycmPijV7zrjmjy/cqiIj0NeEOhab0t/535Nrp4xOuhwdSbvISETmY9bWvzj5gGppbeXZZ5752u19ez13CKiLSF4U2FG784+ssDL48K97ehgsKchQKInJoC20ovLVhZ9ryiXu5uSz++/lFRA5FoQ2F3DQH+PtmnczXzz8yzdwiIuEQ2lDISXNT0EljBlGgcQMRCbHQhkK670UHyM0K7UciIqJQSJatcQMRCbHQ3qeQk3Tw/+LZh0fKg26lvOwsmloj9zHccMGRseciIoey0IZCfEvhmqlj+dyZQSjEhcXXLxjPQy+t4dNnjDng9RMR6Q2hDYVoiyAny7hmavt3+OcEYwqOM+uMw5h1xmG9Uj8Rkd4Q2jGF6ME/+SqkbH1VsYiEWGhDIS8ncvBPvtoo3f0LIiJhEdpQiF5llNwyiJYfZD8pKyLSIzIWCmb2n2a2xMxeM7OHzaw0btr1ZlZrZkvNbFpc+fSgrNbMrstU3QCiFxPlJLUU2scURETCJ5MthfnAUe5+DPAWcD2AmU0ALgcmAtOB/zGzbDPLBu4AzgcmADOCeTOiJUiF5J87THens4hIWGQsFNz9L+7eErx8HqgMnl8E3Ovuje6+AqgFJgePWndf7u5NwL3BvBkxenARANdfkPhdR+3dR2oriEj4HKgxhU8CjwXPK4DVcdPqgrKOyjOiMDfyHUdnjC1PKI/ep1CUF9qrdUUkxLp15DOzJ4BhaSbd4O6PBPPcALQA90QXSzO/kz6g0p6um9ksYBZAVVVVJ2sdrLiDhkBOdhY3XHAkZ40f3KX1iogczLoVCu4+dW/TzWwm8D7gHG/vj6kDRsbNVgmsDZ53VJ78vrOB2QA1NTXd6uexNBmlO5hFJKwyefXRdOBrwPvdPf7X7ucAl5tZvpmNBsYCLwILgLFmNtrM8ogMRs/JVP1ERCRVJjvO/xvIB+Zb5Dcun3f3z7j7G2Z2P/AvIt1KV7t7K4CZfR6YB2QDd7r7G5mqnIaRRURSZSwU3P3wvUy7BbglTflcYG6m6pSWrkAVEYkJ7R3NuuRURCRVaEMhytRSEBGJCX0oiIhIu9CHghoKIiLtQh8KIiLSLrShoHFmEZFUoQ2FKNNIs4hITGhDwXX7mohIitCGQpTaCSIi7UIfCiIi0i60oaCBZhGRVKENhSiNM4uItAttKKihICKSKrShEJXuR3ZERMIqtKGgMQURkVShDYUojSmIiLQLfSiIiEi70IaC7mgWEUkV2lAQEZFUoQ0FDTSLiKQKbShEaaBZRKRd6ENBRETahT4UdPOaiEi7jIeCmX3FzNzMyoPXZmY/MbNaM3vNzI6Pm3emmS0LHjMzXTcREUmUk8mVm9lI4Fzgnbji84GxweMk4GfASWZWBtwE1BD5aqJFZjbH3bdkom6ukWYRkRSZbin8CLiWxO+fuwj4tUc8D5Sa2XBgGjDf3TcHQTAfmJ7h+mmgWUQkTsZCwczeD6xx91eTJlUAq+Ne1wVlHZWnW/csM1toZgvr6+u7VD81FEREUnWr+8jMngCGpZl0A/B14Lx0i6Up872Upxa6zwZmA9TU1HTr8K6GgohIu26FgrtPTVduZkcDo4FXLdI/Uwm8ZGaTibQARsbNXgmsDcrPTCp/ujv12xs1FEREUmWk+8jdF7v7EHevdvdqIgf84919PTAHuCK4CulkYJu7rwPmAeeZ2UAzG0iklTEvE/WLZxpUEBGJyejVRx2YC1wA1AK7gU8AuPtmM/sOsCCY79vuvrkX6iciEloHJBSC1kL0uQNXdzDfncCdB6ZOB+JdREQOLrqjubcrICLSh4Q2FPR7CiIiqUIbClEaZxYRaRf6UBARkXahDQUNNIuIpAptKETpPgURkXahDQU1FEREUoU2FEREJFV4Q0GDCiIiKcIbCuhyVBGRZKEOBRERSRTaUFDnkYhIqtCGAuh7j0REkoU2FDTOLCKSKrShALpxTUQkWWhDQd+SKiKSKrShABpTEBFJFupQEBGRRKENBQ00i4ikCm0ogO5oFhFJFtpQUENBRCRVaEMBwDTULCKSILShoDEFEZFUGQ0FM/uCmS01szfM7Ptx5debWW0wbVpc+fSgrNbMrstk3SJvmPF3EBE5qORkasVmdhZwEXCMuzea2ZCgfAJwOTARGAE8YWbjgsXuAM4F6oAFZjbH3f+VqTqKiEiijIUC8FngVndvBHD3DUH5RcC9QfkKM6sFJgfTat19OYCZ3RvMm5FQ0B3NIiKpMtl9NA443cxeMLO/mdmJQXkFsDpuvrqgrKPyFGY2y8wWmtnC+vr6LldQvUciIom61VIwsyeAYWkm3RCseyBwMnAicL+ZjSH9sdhJH1BpT+fdfTYwG6CmpqZrp/xqKIiIpOhWKLj71I6mmdlngYfc3YEXzawNKCfSAhgZN2slsDZ43lF5RujmNRGRRJnsPvojcDZAMJCcB2wE5gCXm1m+mY0GxgIvAguAsWY22szyiAxGz8lg/UREJEkmB5rvBO40s9eBJmBm0Gp4w8zuJzKA3AJc7e6tAGb2eWAekA3c6e5vZKpy6j0SEUmVsVBw9ybgYx1MuwW4JU35XGBupuqUTHc0i4gkCvEdzWoriIgkC20ogAaaRUSShTYU1FAQEUkV2lAA3bwmIpIs1KEgIiKJQhsK6j0SEUkV2lAAMI00i4gkCG0oaKBZRCRVaEMBNNAsIpIstKGg31MQEUkV2lAA1FQQEUkS7lAQEZEEoQ0FDTSLiKQKbSiAeo9ERJKFOhRERCRRqENBN6+JiCQKbSjo9xRERFKFNhRAv6cgIpIs1KEgIiKJQhsK6jwSEUkV2lAAXZIqIpIstKGgcWYRkVShDQXQJakiIskyFgpmNsnMnjezV8xsoZlNDsrNzH5iZrVm9pqZHR+3zEwzWxY8ZmaqbiIikl5OBtf9feBb7v6YmV0QvD4TOB8YGzxOAn4GnGRmZcBNQA2RceBFZjbH3bdkonL66mwRkVSZ7D5yoCR4PgBYGzy/CPi1RzwPlJrZcGAaMN/dNwdBMB+YnsH6aaBZRCRJJlsK1wDzzOwHRMJnSlBeAayOm68uKOuoPIWZzQJmAVRVVXWpchpoFhFJ1a1QMLMngGFpJt0AnAP8u7s/aGYfBn4FTCX9CbrvpTy10H02MBugpqamy4d3jTOLiCTqVii4+9SOppnZr4EvBS//APwyeF4HjIybtZJI11IdkTGH+PKnu1O/vVFDQUQkVSbHFNYC7wmenw0sC57PAa4IrkI6Gdjm7uuAecB5ZjbQzAYC5wVlGaSmgohIvEyOKXwauN3McoAGgjEAYC5wAVAL7AY+AeDum83sO8CCYL5vu/vmDNZPRESSZCwU3P3vwAlpyh24uoNl7gTuzFSdEt/rQLyLiMjBJeR3NPd2DURE+pYQh4KaCiIiyUIcChpmFhFJFtpQ0JiCiEiq0IYCaExBRCRZqENBREQShTYU1H0kIpIqtKEAYBpqFhFJENpQ0O8piIikCm0ogAaaRUSShTYUNKYgIpIqtKEAunlNRCRZqENBREQShTYU1HskIpIqtKEAYBppFhFJENpQ0ECziEiq0IaCiIikUiiIiEhMaENBdzSLiKQKbSiA7mgWEUkW3lBQQ0FEJPJjMT0AAAkFSURBVEV4QwG1FEREknUrFMzsQ2b2hpm1mVlN0rTrzazWzJaa2bS48ulBWa2ZXRdXPtrMXjCzZWZ2n5nldadu+6KGgohIqu62FF4HLgWeiS80swnA5cBEYDrwP2aWbWbZwB3A+cAEYEYwL8BtwI/cfSywBfhUN+u2T/o9BRGRRN0KBXd/092Xppl0EXCvuze6+wqgFpgcPGrdfbm7NwH3AhdZ5Nbis4EHguXvBi7uTt1ERKTzMjWmUAGsjntdF5R1VD4I2OruLUnlGeO6pVlEJEXOvmYwsyeAYWkm3eDuj3S0WJoyJ30I+V7m76hOs4BZAFVVVR3Ntk8aaBYRSbTPUHD3qV1Ybx0wMu51JbA2eJ6ufCNQamY5QWshfv50dZoNzAaoqanp0im/2gkiIqky1X00B7jczPLNbDQwFngRWACMDa40yiMyGD3HI305TwEfDJafCXTUCukxaiiIiCTq7iWpl5hZHXAK8KiZzQNw9zeA+4F/AY8DV7t7a9AK+DwwD3gTuD+YF+BrwH+YWS2RMYZfdadu+6IhBRGRVPvsPtobd38YeLiDabcAt6QpnwvMTVO+nMjVSQeMfk9BRCRRqO9oFhGRRKENBfUeiYikCm0ogAaaRUSShTYUdPOaiEiq0IYCoKaCiEiS0IaC2gkiIqlCGwqghoKISLJQh4KIiCQKbyio/0hEJEV4QwHd0Swikiy0oeBqKoiIpAhtKIAGmkVEkoU6FEREJFFoQ0E3NIuIpAptKIB+jlNEJFloQ0EtBRGRVKENBQDTULOISILQhoIuSRURSRXaUACNKYiIJAt1KIiISKLQhoIGmkVEUoU2FEREJFVoQ0ENBRGRVN0KBTP7kJm9YWZtZlYTV36umS0ys8XBv2fHTTshKK81s59Y8FWlZlZmZvPNbFnw78Du1G0/65/ptxAROah0t6XwOnAp8ExS+UbgQnc/GpgJ/CZu2s+AWcDY4DE9KL8OeNLdxwJPBq8zRmMKIiKpuhUK7v6muy9NU/6yu68NXr4BFJhZvpkNB0rc/Tl3d+DXwMXBfBcBdwfP744rzxi1E0REEh2IMYUPAC+7eyNQAdTFTasLygCGuvs6gODfIR2t0MxmmdlCM1tYX1+foWqLiIRPzr5mMLMngGFpJt3g7o/sY9mJwG3AedGiNLN1uiPH3WcDswFqamq62BGk/iMRkWT7DAV3n9qVFZtZJfAwcIW7vx0U1wGVcbNVAtFupnfNbLi7rwu6mTZ05X07V8dMv4OIyMElI91HZlYKPApc7+7/iJYH3UI7zOzk4KqjK4Boa2MOkUFpgn/32grpLg00i4ik6u4lqZeYWR1wCvComc0LJn0eOBy40cxeCR7RMYLPAr8EaoG3gceC8luBc81sGXBu8Dqj1FIQEUm0z+6jvXH3h4l0ESWX3wzc3MEyC4Gj0pRvAs7pTn06Qw0FEZFUob2jGfR7CiIiyUIdCiIikii0oeAaaRYRSRHaUAANNIuIJOvWQPPBrKa6jB0NLb1dDRGRPiW0oXD1WYf3dhVERPqcUHcfiYhIIoWCiIjEKBRERCRGoSAiIjEKBRERiVEoiIhIjEJBRERiFAoiIhJjB/t3AJlZPbCqi4uXAxt7sDoHA21zOGibw6E72zzK3QcnFx70odAdZrbQ3Wt6ux4HkrY5HLTN4ZCJbVb3kYiIxCgUREQkJuyhMLu3K9ALtM3hoG0Ohx7f5lCPKYiISKKwtxRERCSOQkFERGJCGwpmNt3MlppZrZld19v16QlmNtLMnjKzN83sDTP7UlBeZmbzzWxZ8O/AoNzM7CfBZ/CamR3fu1vQdWaWbWYvm9mfg9ejzeyFYJvvM7O8oDw/eF0bTK/uzXp3lZmVmtkDZrYk2N+nHOr72cz+Pfi7ft3Mfm9mBYfafjazO81sg5m9HlfW6f1qZjOD+ZeZ2czO1CGUoWBm2cAdwPnABGCGmU3o3Vr1iBbgy+5+JHAycHWwXdcBT7r7WODJ4DVEtn9s8JgF/OzAV7nHfAl4M+71bcCPgm3eAnwqKP8UsMXdDwd+FMx3MLodeNzdxwPHEtn2Q3Y/m1kF8EWgxt2PArKByzn09vNdwPSksk7tVzMrA24CTgImAzdFg2S/uHvoHsApwLy419cD1/d2vTKwnY8A5wJLgeFB2XBgafD858CMuPlj8x1MD6Ay+M9yNvBnwIjc5ZmTvL+BecApwfOcYD7r7W3o5PaWACuS630o72egAlgNlAX77c/AtENxPwPVwOtd3a/ADODnceUJ8+3rEcqWAu1/YFF1QdkhI2guHwe8AAx193UAwb9DgtkOlc/hx8C1QFvwehCw1d1bgtfx2xXb5mD6tmD+g8kYoB74v6DL7JdmVsQhvJ/dfQ3wA+AdYB2R/baIQ3s/R3V2v3Zrf4c1FCxN2SFzba6Z9QceBK5x9+17mzVN2UH1OZjZ+4AN7r4ovjjNrL4f0w4WOcDxwM/c/ThgF+1dCukc9NscdH9cBIwGRgBFRLpPkh1K+3lfOtrGbm17WEOhDhgZ97oSWNtLdelRZpZLJBDucfeHguJ3zWx4MH04sCEoPxQ+h1OB95vZSuBeIl1IPwZKzSwnmCd+u2LbHEwfAGw+kBXuAXVAnbu/ELx+gEhIHMr7eSqwwt3r3b0ZeAiYwqG9n6M6u1+7tb/DGgoLgLHBlQt5RAas5vRynbrNzAz4FfCmu/9X3KQ5QPQKhJlExhqi5VcEVzGcDGyLNlMPFu5+vbtXuns1kf34V3f/KPAU8MFgtuRtjn4WHwzmP6jOIN19PbDazI4Iis4B/sUhvJ+JdBudbGb9gr/z6DYfsvs5Tmf36zzgPDMbGLSwzgvK9k9vD6r04mDOBcBbwNvADb1dnx7aptOINBNfA14JHhcQ6Ut9ElgW/FsWzG9ErsJ6G1hM5MqOXt+Obmz/mcCfg+djgBeBWuAPQH5QXhC8rg2mj+ntendxWycBC4N9/Udg4KG+n4FvAUuA14HfAPmH2n4Gfk9kzKSZyBn/p7qyX4FPBtteC3yiM3XQ11yIiEhMWLuPREQkDYWCiIjEKBRERCRGoSAiIjEKBRERiVEoiIhIjEJBRERi/j/rP5U7qccBCwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sarsa(env, num_episodes, discount_factor=1.0, alpha=0.5, epsilon=0.1, Q=None):\n",
    "    \"\"\"\n",
    "    SARSA algorithm: On-policy TD control. Finds the optimal epsilon-greedy policy.\n",
    "    \n",
    "    Args:\n",
    "        env: OpenAI environment.\n",
    "        num_episodes: Number of episodes to run for.\n",
    "        discount_factor: Gamma discount factor.\n",
    "        alpha: TD learning rate.\n",
    "        epsilon: Probability to sample a random action. Float between 0 and 1.\n",
    "        Q: hot-start the algorithm with a Q value function (optional)\n",
    "    \n",
    "    Returns:\n",
    "        A tuple (Q, stats).\n",
    "        Q is the optimal action-value function, a dictionary mapping state -> action values.\n",
    "        stats is a list of tuples giving the episode lengths and rewards.\n",
    "    \"\"\"\n",
    "    \n",
    "    # The final action-value function.\n",
    "    # A nested dictionary that maps state -> (action -> action-value).\n",
    "    if Q is None:\n",
    "        Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "    \n",
    "    # Keeps track of useful statistics\n",
    "    stats = []\n",
    "    \n",
    "    # The policy we're following\n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, env.action_space.n)\n",
    "    \n",
    "\n",
    "    for i_episode in tqdm(range(num_episodes)):\n",
    "        i = 0\n",
    "        R = 0\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        s = env.reset()\n",
    "        a = policy(s)\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            observation,reward,done,info = env.step(a)\n",
    "            a_prime = policy(observation) #Can decrease epsilon over time to converge\n",
    "            \n",
    "            current_Q = Q[s][a]\n",
    "            Q[s][a] = current_Q + alpha * (reward + discount_factor * Q[observation][a_prime] - current_Q)\n",
    "            \n",
    "            a = a_prime\n",
    "            s = observation\n",
    "            \n",
    "            R += reward\n",
    "            i += 1\n",
    "        \n",
    "        stats.append((i, R))\n",
    "    episode_lengths, episode_returns = zip(*stats)\n",
    "    return Q, (episode_lengths, episode_returns)\n",
    "\n",
    "Q_sarsa, (episode_lengths_sarsa, episode_returns_sarsa) = sarsa(env, 1000)\n",
    "\n",
    "# We will help you with plotting this time\n",
    "plt.plot(episode_lengths_sarsa)\n",
    "plt.title('Episode lengths SARSA')\n",
    "plt.show()\n",
    "plt.plot(episode_returns_sarsa)\n",
    "plt.title('Episode returns SARSA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1e8df3908ce548708b64f69e11a34896",
     "grade": false,
     "grade_id": "cell-0eaf4b925ab3ea34",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We learn the optimal (non-exploring) policy while using another policy to do exploration, which is where we arrive at _off-policy_ learning. In the simplest variant, we learn our own value by bootstrapping based on the action value corresponding to the best action we could take, while the exploration policy actual follows the $\\epsilon$-greedy strategy. This is known as Q-learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "954556134388a34f8d4b9a07834180c5",
     "grade": true,
     "grade_id": "cell-a87637d2e582fec0",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 3104.28it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEICAYAAACwDehOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXxddZ3/8dcne5o2S5uWpHtpy1JoWRooICh7W2TTAQVGqYgwOrjMiKMiOogKivpzwWEcqzIKOrIJWqHQoaAsIqXpYAulW9pSGrok6Zq0zf75/XFOkpt7b9IluU2T834+Hnlw7/d877nfc0+57/v9fs9i7o6IiAhAWl83QEREjhwKBRERaadQEBGRdgoFERFpp1AQEZF2CgUREWmnUJCUMLOnzWxOL6/z62b2m95c50DWl5+Xmf2XmX2tL95bekahIF0ys7fNbJ+Z1cX8/ceBvNbdZ7v7r1PdxlQ50gLIzArN7KdmtsXM9prZG70dur3J3T/p7t/s63bIwcvo6wbIEe8yd1/Y143oTWaW4e7N/eU9zCwLWAhUAWcClcAFwK/NrMDd7+2N9zmI9qT885O+o56CHBIz+5iZ/dXMfmJmu8xspZldELP8L2b2ifDxJDN7IaxXY2YPx9Q7y8wWh8sWm9lZMcsmhK+rNbNngeK4NpxhZq+Y2U4zW2pm53bT3rfN7EtmtgzYY2YZZjbSzH5vZtVmtt7MPhvWnQV8Bfhw2DtaGrOOC2PW2d6bMLPxZuZmdqOZvQM8H1M2x8zeCbf99pjXn25m5Wa228y2mtkPumj+R4GxwNXuvt7dm9z9GeCzwLfMbEi3O+sAPi8zu8HMVoSf9Toz+6eYZeeaWWX4+W0B/jum7FYzqzKzzWZ2Q8xrfmVm34p7fVd1h5nZn8LPYbGZfcvMXj6QbZLep1CQnpgBrCP4sr4DeNzMhiap903gf4EiYDTwE4Cw7lPAvcAw4AfAU2Y2LHzd/wBLwvV/E2gfLjGzUeFrvwUMBb4A/N7MhnfT3muB9wOFQCvwJ2ApMIrgl/e/mNnM8Av3buBhdx/s7icdxGfyPuB4YGZM2dnAseF7/LuZHR+W/xj4sbvnAxOBR7pY50XA0+6+J67898Ag4Iz9NeoAPq8q4FIgH7gB+KGZnRqzipLwdeOAm2PKCgg+vxuB+8ysqIsmdFf3PmBPWGcOMftZDj+FguzPH8Jflm1/N8UsqwJ+FP5yfRhYRfClG6+J4MtkpLvXu3vbr8D3A2vc/UF3b3b33wErgcvMbCxwGvA1d29w9xcJvsTbfASY7+7z3b3V3Z8FyoFLutmWe919o7vvC9c93N2/4e6N7r4O+DlwzUF+PvG+7u57wvdoc6e773P3pQQh1BYyTcAkMyt29zp3f7WLdRYDm+MLwyGcGqC7IGzT7efl7k+5+1oPvEAQ4ufEvL4VuCPcF23b1gR8I9z/84E6gvBLJmldM0sH/iFc9153fwvot3NRA4FCQfbnSncvjPn7ecyyd73zFRU3ACOTrOOLgAGvmdlyM/t4WD4yfE2sDQS/JkcCO+J+HcfWHQdcHRtYBL/IS7vZlo1xrx8Z9/qvAEd18/oDsTFJ2ZaYx3uBweHjG4FjgJXhsMmlXayzhiTbZWYZBIFRbWb/aB0HAzydZB3dfl5mNtvMXjWz7eGyS+g8XFft7vVx69wWN7cQu23xuqo7nGBuM/ZzS/YZymGiiWbpiVFmZjHBMBaYF1/J3bcANwGY2dnAQjN7EdhE8GUVayzwDMEv4yIzy4sJhrFA23ttBB5095s4cLEBthFY7+6TD6Bumz0EwzVtSg7wdcnfwH0NcK2ZpQEfBB4zs2FJhokWAnfHfRYQ/MJuAl5z913Ab7t5uy4/LzPLJhiKuh74o7s3mdkfCIL8oLfrIFUDzQTDiqvDsjEpei85AOopSE+MAD5rZplmdjXBWPr8+EpmdrWZjQ6f7iD4gmkJ6x5jZteFE78fBqYAT7r7BoLhjTvNLCsMk8tiVvsbgmGmmWaWbmY54YTmaA7Ma8DucPI0N1zHiWZ2Wrh8KzA+/MJu83fgmnB7y4CrDvC9kjKzj5jZcHdvBXaGxS1Jqj5IcMTRo+HkdaaZzSSYi/luGAj7093nlQVkE35Bm9ls4OKebNuBcvcW4HHg62Y2yMyOIwgn6SMKBdmfP1nn8xSeiFm2CJhMMLxxF3CVu29Lso7TgEVmVkfQk/hceBTNNoLJzVuBbQTDTJe6e034uusIJrO3E0xkP9C2QnffCFxBMORTTfBL+N84wH/T4ZfRZcDJwPpwG35BMBkK8Gj4321m9n/h468RTAjvAO4kmAjviVnA8vBz+TFwTZIhGty9AbiQYBsXAfsIelM/CtuxX919Xu5eS3Ak0yME23YdSXp8KfRpgs99C0EA/g5oOIzvLzFMN9mRQ2FmHwM+4e5n93VbosbMMoGngXeBj/kA+5/YzO4BStxdRyH1AfUURPoZd28imE9YS9dH+/QbZnacmU2zwOkEE/BP7O91khqaaBbph8J5hG/0dTt6yRCCIaORBIc5/z/gj33aogjT8JGIiLTT8JGIiLTr98NHxcXFPn78+L5uhohIv7JkyZIad084G77fh8L48eMpLy/v62aIiPQrZhZ/NQFAw0ciIhJDoSAiIu0UCiIi0u6ICwUzm2Vmq8yswsy+3NftERGJkiMqFMJrq98HzCa4MNq1Zjalb1slIhIdR1QoAKcDFe6+zt0bgYcILuIlIiKHwZEWCqPofIONyrCsEzO72YJ725ZXV1cftsaJiAx0R9p5CpakLOE6HO4+F5gLUFZWdsRcp8PdqW1oJj8ns8s6zS2t1De3kpluvP7OTk4ZW0h2RjoATS2tPFK+kcLcLF5aU81tlxzP6q21rK2qY+roAqp2NzBtdAFLNuzgb+u24Q552ekcXTyY4iHZ1NQ2cMbEYTy5dBNLNuxg+rgiSgpyWFe9h8JBmWzZVc/E4YOpb25hT0MLNXUNVNU2MHF4HjNPKOHF1dVMG11I+dvbeXvbXmadWMLqrbU0NLcyKCudGROGUjw4m2ff2kpzayvDh2RTPDibF1dXk5edQV5WBkNyMhg+JJu3Nu2mudV5d+c+8nMyGZqXyd7GFkoKcrh02kj+Z9EGNu+q58RRBeze18S7O/exakstJQU5jB+WR9GgTGrqGiktzKG11alvamXjjr0cX5pPuhnravZQNCiTLbvrmVCcx6jCXJZV7mLjjr1MG1VAc6uzp6GFhuYWRhXlhvsHauubyc5I473HDOf+v65nVGEuk0cM5pW12zhz4jBWbN5NXlYGBYMyqa5tIDPdSDOjcFAWO/Y0MvmowdQ1NFO5Yx9jhw5izdY6Wtyprm3gzInDWL5pFw1NwWczsjCHZZW7yMpI45xJw1lTVUtGmjE0L5thg7P4yfNrGDt0ECMLcklLMyYU57FtTyPVtQ24O2dNLGbF5t0MzslgX2MLL62pJj3NmFJawNhhuexrbKWppZWq2npKCnJpaWmlqraBEUOyyc/NZF9TCzW1jUwdnc/CFVUMy8sCoLGllbysDE4dW8Tit7czoTiPddV1bNvTyDFHDaF8ww7cneNKhlBakMsb7+4iNyud7XWNDB+STeGgTJpbnQ3b9rCvsYXPXDCZuvpm3ty0i1fWbmN0YS61Dc00NbeSk5lOZnoax5cOYVRhLlW1DbS68+dV1YwqzOWYowbz8poaBudkUJAb/H9z7rHD2bBtL2dPKuZ3r21kTVUtJ48p5LzjRrBjTyMLlm9hw7a95GSmc+UpI2lucYYNzuKvFdvYsrueS6eVsnNvE9W1DTS1tFJSkMMpY4v4+zs7KS3MobnFeWzJRrIy0jh70nDWVtdx0uhCpo4qYHd9Ey+sruacycW8snYba6vqGFecx+QRg1m+aTdjhw7iqPxsnl9ZRfHgbJpaWsnKSOOEkQWcMDKfhxZvpLXVGTM0l9ff2Ul1bQM5memcNn4oa6vrOHlMIX9ZVc2Jo/IpHhysZ9ueRkoLchgzdBAThuXxzva9AOxpaGbFlt00tTh5WelMPmoINXUNfLhsDNV1DeTnZDK+eFD790dvOaKufWRmZxLc43Zm+Pw2AHf/dlevKSsr81SevLavsYXcrOQf+t7GZrIz0tmyu543Knfx20UbeGlNDTMmDKW+uZUxRbk8uWwzN7xnPFeePIpbH11KRVVdp3V8uGwM5x03gu//76qEZSIi3Vn4+fcxaURXd0DtnpktcfeyhPIjLBQyCG7JdwHBteIXA9e5+/KuXtMboXD7E2/w5qbd/Pz66Xz3mVU8tqQSgKz0NBpbWgG45byJnD5hGOdMKiYtzdjT0MwJdyzgpnMm8POX1vfo/Q/Fp86dyMwTSli+aRe3P/EmAJNGDKZoUCaXThvJiaPyGZSVwZcff4O1VXXUNQS3x504PI87Lz+Rn724lpfW1PCzj07nnmdWsq56D/9+6RR27G3k0mkj+eGzq3lm+RY+c/4kfvJ8Rfv7Fg/OZvq4Qj5UNobbn3iTLbvruea0MTy0eCNHF+dxfGk+T72xmSc/czart9ayaN12Hi7vGBG8/KSRzFu6qf35cSVDGD4km+yMdBau2MqMCUP58TWn8LvX3mFUYS5f/P0ypo8r4rJppdw1fwVNLc5HzhjL5BFDOGviMJZW7uILjy5tX9/1Z45jSmk+RXlZ7N7XREVVHSMLczlhZD6rt9bx6JKNrN5Sy1mTipl1Qgl7G5up3Bn86n9k8UY+c/5k1tfs4eHyjZw9qZiMNGN1GNYvru4Yqvz8RccwpTSf8cV5/HbRBv77r28D8MFTR3Ha+KFkZ6Tx+UeCdk0ozmN9zR7S04yzJg7jpTU1xHr/tFKeWraZ90waxqad9cw+sYS/rt1GdnoaHz97PJ/8TXCPn+njiph9Ygl/WraZZZU7GZaXTU1dA5dOK+X40ny+t2AVALNOKOGfz5vIys215Odmct+fK3jj3Y6bs502vojFb+8A4N5rT6Giqo4XVlVx8phCLppSQlVtfXvb2/zqhtMYlJXB0LwsXllbQ31TC5t21lNRVcfLFZ235wsXH8OvXtlATV3HfXLGDh2E47y7Yx9fmnUcu+ub2L2vmQdfTXpSbScfKhtNTmY6D/wtqDv3o9MZmpfFY0sqeWxJJc2twXfYP733aH724rr2bdy1r4mbzjma+qYWnnj9XTbvqqe0IIc1W+uYcfQwFq7YCsAPPnQSc19cx8ottQDkZKbxz+dOYnzYg1q6cSfnHzeCZ1dUdfo3MDg7g6aWVhqaW5k+roglG3Zw9fTRfOw947n3uTW875gR7K5v4jevbqByx76k25adkca3rjyRnXubeGVtDQ7kZKTzzPItnDymkLJxRfzi5Y7vl9FFue3r+t5V05h1YglDuhmZ6E6/CAUAM7uE4I5S6cD97n5Xd/V7IxTGf/mpA64764QSbrvkOF6uqGn/Mu4tw/KyuGRqaaf/UY4uzuPa08eSnZnGiCHZlBTk8r0FK/nlnNPIyQx6MLvrm8hMS+uyRwOwedc+6ptamVCcB0B9UwvLN+1m+rgi9jW20NTa2mnYy93527ptzJgwjE/8ejG765v55ZwyCgdldVrvkg3bOa4kn+YWJzcrnayMxGmqtdV1zH1hHV+//ARys9J5o3IXl/3Hy2SkGRV3X9LtZ7KtroGC3Ewy0rue/mpqaaW2vpmiQZmYJRuB7B1bdtVzxrefY/iQbBbffmGnZfVNLTQ0t7YPgQAc+9WnyUxPo/yrF9LQ1ErBoGBZ/L+3t7/z/m7fd211HY+WV/LZCyYxKKtjxLe11dm2JxjS2Z+9jc3c9EA5t5w7ienji/j2/JX86pW3WX7nTPKyE0eRK6rq2LhjL1t3BTeC+/BpY5J+tu7OcyuqmDq6gKPyc9rLG5pb+MVL65kyMp+Fb23lS7OPSxhWdXce/793Ob40n9r6Jj4891UAPv6eCVw3Ywz/9cI6Fq3fxktfPH+/29emtr6JzPS09v83urNo3TbKN+zglvMmAVC5Yy9n3/NnPnP+JG69OPltKqprGxiWl0VaWvBZ7K5vYkPNXqaOLkhav83Ct7byyd8s4anPnsOKzcH/d4Oy0hk2OHHfuTuvrtvO6ROGkp5mbNy+l1fXbWNfUwvXnT6WDdv3snpLLbOnlu53G7vTb0LhYPU0FH7+4jrumr+ix+0oLchh866EOykesMtPGsm9154CwKwfvcjKLbXM/eh0LppyVEq/6PpKXUMz7n7Iv3L6grtz9/wVfOCU0UwZmb/f+rX1TZgZg+O+dNtC4dl/fS+DczIoLchNSXu709zSyva9jYwYkrP/yofJPz1YznuPGc4/zhjXZ22oqq2nMDcr6Y+bgUah0IWD6SV05wOnjOKJ19/tVPbmnTM5+57nmTh8MLdefAzX/XwR93+sjKOLB3Pu9/8CwLKvX8y+xhYKcjPbf928tKaaLz62jOdufV+nX4YyMCzZsIMdexq5cMpRfd0UibCuQkHfOD10zuRiXlpTw77GFr531TR27G3k7vkrAcjLSuf1r10EgJm1DxPs2tcEBOOs+TmZCd3qcyYP52+3XXAYt0IOp+njivq6CSJdUij00LnHjuClNTXUN7dwddkYACYfNYQXVlV3OexTkJvJV99/PBccr1+KInJkiXQo9MbQWUk4uTYsr2PC6LxjR3DesSO6fd0nzjm6x+8tItLbBv5sSjcOdWL47g9MbX884+ihfP/qk/j65bpEk4j0f5HuKZz1ned7vI6sjDSumj66F1ojItL3It1TOFSTj+o4gzCrm+PnRUT6m0j3FA7Fi/92HmOHDWp/rlAQkYFE32gHKTYQgPYzG0VEBgKFQhK/uuG0vm6CiEifiGwotF0gLplzYw4nbbtWULyfXHsKl500stfbJSLSlyI7p/DVJ944oHrZXVwD5bKTRioURGTAiWxPYevuhv1XAu7+4FQ+csbYFLdGROTIENlQ6O4y07FGFuTyrSun7r+iiMgAENlQ6GpYKF66ji4SkQhRKIROGVuYtF5GGAqnjC3kQ2U6c1lEBrbITjRPPmpI++N7/mEq7582khPvWJBQr+08hCf++T2HrW0iIn0lsj2F/JyOPDyuJD/h7lhtMjR8JCIREtlQiL1oduy8wYjwfrdtYaA5BRGJksgOH8Vq++JfesfFZKYHjy+ZWsq8pZsUCiISKZENhdj767T1CgpyO26L+f2rT+IrlxxPpi54JyIRom88kl/ULisjjZKCnD5ojYhI31EooMlkEZE2kQ2F2Pszp5lCQUQEIhwKsTLSFQoiIpDCUDCz75nZSjNbZmZPmFlhzLLbzKzCzFaZ2cyY8llhWYWZfTlVbYO4Q1LVUxARAVLbU3gWONHdpwGrgdsAzGwKcA1wAjAL+E8zSzezdOA+YDYwBbg2rJtyunuaiEggZaHg7v/r7m13snkVaLtw0BXAQ+7e4O7rgQrg9PCvwt3XuXsj8FBYN0Xt63isiWYRkcDhmlP4OPB0+HgUsDFmWWVY1lV5AjO72czKzay8urq6x41TT0FEJNCjk9fMbCFQkmTR7e7+x7DO7UAz8Nu2lyWp7yQPKE9ShrvPBeYClJWVJa1zMNRTEBEJ9CgU3P3C7pab2RzgUuAC7zgGtBIYE1NtNLApfNxVea+LTRIdkioiEkjl0UezgC8Bl7v73phF84BrzCzbzCYAk4HXgMXAZDObYGZZBJPR81LVvlgKBRGRQCqvffQfQDbwrAVfuq+6+yfdfbmZPQK8RTCsdIu7twCY2aeBBUA6cL+7L09V49o6LtefOa79IngiIlGXslBw90ndLLsLuCtJ+XxgfqralMwXZh6LqacgIgLojGYREYkR+VBQH0FEpEPkQ0FERDpENhS8x2c3iIgMPJENhTaaZBYR6RDZUPDkJ0uLiERaZEOhjfoJIiIdIhsKmlMQEUkU2VBooykFEZEOkQ8FERHpENlQ0OiRiEiiyIZCG9NUs4hIu8iGgiaaRUQSRTYU2miiWUSkQ2RDQSeviYgkimwoiIhIIoWCiIi0i2woaKJZRCRRZEOhjSaaRUQ6RD4URESkQ+RDQSeviYh0iGwouCYVREQSRDYU2mhOQUSkQ+RDQUREOkQ2FDR6JCKSKOWhYGZfMDM3s+LwuZnZvWZWYWbLzOzUmLpzzGxN+Dcn1W0D3Y5TRCRWRipXbmZjgIuAd2KKZwOTw78ZwE+BGWY2FLgDKCO43cESM5vn7jtS0TZ1FEREEqW6p/BD4It0/g6+AnjAA68ChWZWCswEnnX37WEQPAvMSnH7MM00i4i0S1komNnlwLvuvjRu0ShgY8zzyrCsq/Jk677ZzMrNrLy6uroXWy0iEm09Gj4ys4VASZJFtwNfAS5O9rIkZd5NeWKh+1xgLkBZWdkhjQRpollEJFGPQsHdL0xWbmZTgQnA0nB4ZjTwf2Z2OkEPYExM9dHAprD83Ljyv/SkfQdCg0ciIh1SMnzk7m+4+wh3H+/u4wm+8E919y3APOD68CikM4Bd7r4ZWABcbGZFZlZE0MtYkIr2gW6yIyKSTEqPPurCfOASoALYC9wA4O7bzeybwOKw3jfcfXuqG6N5ZhGRDoclFMLeQttjB27pot79wP2Hp02H411ERPqXyJ7R3EaHpIqIdIh8KIiISIfIhoJGj0REEkU2FEREJFF0Q0EzzSIiCaIbCuhwVBGReJENBfUTREQSRTYUQJe4EBGJF+lQEBGRziIbCppnFhFJFNlQAJ3NLCISL7KhoKukiogkimwogCaaRUTiRTYUNKcgIpIosqEAOnlNRCRepENBREQ6i2woaPRIRCRRZEMBwDTVLCLSSWRDQRPNIiKJIhsKgI5JFRGJE9lQ0MlrIiKJIhsKoI6CiEi8SIeCiIh0Ft1Q0OiRiEiC6IYCOqNZRCReSkPBzD5jZqvMbLmZfTem/DYzqwiXzYwpnxWWVZjZl1PZNnUUREQSZaRqxWZ2HnAFMM3dG8xsRFg+BbgGOAEYCSw0s2PCl90HXARUAovNbJ67v5WyNmqqWUSkk5SFAvAp4Dvu3gDg7lVh+RXAQ2H5ejOrAE4Pl1W4+zoAM3sorJuSUHCdvSYikiCVw0fHAOeY2SIze8HMTgvLRwEbY+pVhmVdlScws5vNrNzMyqurqw+5gZpTEBHprEc9BTNbCJQkWXR7uO4i4AzgNOARMzua5KcHOMkDKunPeXefC8wFKCsr009+EZFe0qNQcPcLu1pmZp8CHvdgnOY1M2sFigl6AGNiqo4GNoWPuyrvdRo9EhFJlMrhoz8A5wOEE8lZQA0wD7jGzLLNbAIwGXgNWAxMNrMJZpZFMBk9L4Xt0zSziEicVE403w/cb2ZvAo3AnLDXsNzMHiGYQG4GbnH3FgAz+zSwAEgH7nf35alqnDoKIiKJUhYK7t4IfKSLZXcBdyUpnw/MT1Wb4plmmkVEOonsGc2aUxARSRTZUADNKYiIxIt0KIiISGeRDQXdZEdEJFFkQwHQ+JGISJzIhoImmkVEEkU2FEAdBRGReJEOBRER6UyhICIi7SIdCjqjWUSks8iGgm6yIyKSKLKhALrJjohIvMiGgvoJIiKJIhsKoENSRUTiRToURESks8iGguaZRUQSRTYUQIekiojEi2wo6CqpIiKJIhsKoIlmEZF4kQ0FzSmIiCSKbCiATl4TEYkX6VAQEZHOIhsKGj0SEUkU2VAIaPxIRCRWZENBE80iIolSFgpmdrKZvWpmfzezcjM7PSw3M7vXzCrMbJmZnRrzmjlmtib8m5OqtnW8X6rfQUSkf8lI4bq/C9zp7k+b2SXh83OB2cDk8G8G8FNghpkNBe4AygiG/JeY2Tx335Ga5qmrICISL5XDRw7kh48LgE3h4yuABzzwKlBoZqXATOBZd98eBsGzwKwUtk8zCiIicVLZU/gXYIGZfZ8gfM4Ky0cBG2PqVYZlXZUnMLObgZsBxo4d27utFhGJsB6FgpktBEqSLLoduAD4V3f/vZl9CPglcCHJf6B7N+WJhe5zgbkAZWVlhzQOpIlmEZFEPQoFd7+wq2Vm9gDwufDpo8AvwseVwJiYqqMJhpYqCeYcYsv/0pP27Y8mmkVEOkvlnMIm4H3h4/OBNeHjecD14VFIZwC73H0zsAC42MyKzKwIuDgsSwn1FEREEqVyTuEm4MdmlgHUE84BAPOBS4AKYC9wA4C7bzezbwKLw3rfcPftKWwfpqlmEZFOUhYK7v4yMD1JuQO3dPGa+4H7U9WmTu+lQ1JFRBJE9oxm0JyCiEi8SIeCiIh0FtlQ0ESziEiiyIYC6IxmEZF4kQ0FdRRERBJFNhQATDPNIiKdRDYUNKcgIpIosqEgIiKJFAoiItIusqGgM5pFRBJFNhRAZzSLiMSLbiiooyAikiC6oYB6CiIi8SIbCuooiIgkimwogO6nICISL9KhICIinUU2FFynNIuIJIhsKIAmmkVE4kU2FNRPEBFJFNlQAN1PQUQkXqRDQUREOotsKGieWUQkUWRDAXSTHRGReJENBXUUREQSRTYUQBPNIiLxIhsKOnlNRCRRj0LBzK42s+Vm1mpmZXHLbjOzCjNbZWYzY8pnhWUVZvblmPIJZrbIzNaY2cNmltWTth3YBqT8HURE+pWe9hTeBD4IvBhbaGZTgGuAE4BZwH+aWbqZpQP3AbOBKcC1YV2Ae4AfuvtkYAdwYw/bJiIiB6lHoeDuK9x9VZJFVwAPuXuDu68HKoDTw78Kd1/n7o3AQ8AVFhwGdD7wWPj6XwNX9qRt+217KlcuItJPpWpOYRSwMeZ5ZVjWVfkwYKe7N8eVJ2VmN5tZuZmVV1dXH3IjNXokItJZxv4qmNlCoCTJotvd/Y9dvSxJmZM8hLyb+km5+1xgLkBZWdmh/ehXV0FEJMF+Q8HdLzyE9VYCY2KejwY2hY+TldcAhWaWEfYWYuunjE5eExHpLFXDR/OAa8ws28wmAJOB14DFwOTwSKMsgsnoeR4cH/pn4Krw9XOArnohvcLVVRARSdDTQ1I/YGaVwJnAU2a2AMDdlwOPAG8BzwC3uHtL2Av4NLAAWAE8EtYF+BLweTOrIJhj+GVP2nZA7U/1G4iI9DP7HT7qjrs/ATzRxbK7gLuSlM8H5icpX0dwdJKIiPSRCJ/R3NctEBE58tkT20AAAAabSURBVEQ2FEC34xQRiRfZUFBPQUQkUWRDAcA01Swi0klkQ0GHpIqIJIpsKIDmFERE4kU6FEREpLPIhoImmkVEEkU2FEREJFFkQ0EdBRGRRJENBdBVUkVE4kU2FDSnICKSKLKhALpKqohIvEiHgoiIdBbhUND4kYhIvAiHgs5oFhGJF9lQ0ESziEiiyIYCqKcgIhIvsqGgjoKISKLIhgLofgoiIvEiHQoiItJZZEPBNdMsIpIgsqEAmmgWEYmX0dcN6Ctl44dSW9/c180QETmiRDYUbjlvUl83QUTkiNOj4SMzu9rMlptZq5mVxZRfZGZLzOyN8L/nxyybHpZXmNm9Fl6/2syGmtmzZrYm/G9RT9omIiIHr6dzCm8CHwRejCuvAS5z96nAHODBmGU/BW4GJod/s8LyLwPPuftk4LnwuYiIHEY9CgV3X+Huq5KUv+7um8Kny4EcM8s2s1Ig393/5sHhPw8AV4b1rgB+HT7+dUy5iIgcJofj6KN/AF539wZgFFAZs6wyLAM4yt03A4T/HdHVCs3sZjMrN7Py6urqFDVbRCR69jvRbGYLgZIki2539z/u57UnAPcAF7cVJal20CcMuPtcYC5AWVmZTjgQEekl+w0Fd7/wUFZsZqOBJ4Dr3X1tWFwJjI6pNhpoG2baamal7r45HGaqOpT3FRGRQ5eS4SMzKwSeAm5z97+2lYfDQrVmdkZ41NH1QFtvYx7BpDThf7vthYiISO/r6SGpHzCzSuBM4CkzWxAu+jQwCfiamf09/GubI/gU8AugAlgLPB2Wfwe4yMzWABeFz0VE5DCy/n4NIDOrBjYc4suLCQ6fjRJtczRom6OhJ9s8zt2Hxxf2+1DoCTMrd/ey/dccOLTN0aBtjoZUbHOkL4gnIiKdKRRERKRd1ENhbl83oA9om6NB2xwNvb7NkZ5TEBGRzqLeUxARkRgKBRERaRfZUDCzWWa2Kryvw4C4TLeZjTGzP5vZivA+F58Ly5Peq8IC94afwTIzO7Vvt+DQmVm6mb1uZk+GzyeY2aJwmx82s6ywPDt8XhEuH9+X7T5UZlZoZo+Z2cpwf5850Pezmf1r+O/6TTP7nZnlDLT9bGb3m1mVmb0ZU3bQ+9XM5oT115jZnGTv1ZVIhoKZpQP3AbOBKcC1Zjalb1vVK5qBW939eOAM4JZwu7q6V8VsOu5rcTPBvS76q88BK2Ke3wP8MNzmHcCNYfmNwA53nwT8MKzXH/0YeMbdjwNOItj2AbufzWwU8FmgzN1PBNKBaxh4+/lXdNxjps1B7VczGwrcAcwATgfuOKiblrl75P4ILsuxIOb5bQTXaerztvXydv6R4JIhq4DSsKwUWBU+/hlwbUz99nr96Y/gworPAecDTxJcjbcGyIjf38AC4MzwcUZYz/p6Gw5ye/OB9fHtHsj7meAS+xuBoeF+exKYORD3MzAeePNQ9ytwLfCzmPJO9fb3F8meAh3/wNrE3tdhQAi7y6cAi+j6XhUD5XP4EfBFoDV8PgzY6e7N4fPY7Wrf5nD5rrB+f3I0UA38dzhk9gszy2MA72d3fxf4PvAOsJlgvy1hYO/nNge7X3u0v6MaCr1yX4cjlZkNBn4P/Iu77+6uapKyfvU5mNmlQJW7L4ktTlLVD2BZf5EBnAr81N1PAfbQ/e1r+/02h8MfVwATgJFAHsHwSbyBtJ/3p6tt7NG2RzUUKoExMc9j7+vQr5lZJkEg/NbdHw+Lt4b3qCDuXhUD4XN4D3C5mb0NPEQwhPQjoNDM2u4XErtd7dscLi8Ath/OBveCSqDS3ReFzx8jCImBvJ8vBNa7e7W7NwGPA2cxsPdzm4Pdrz3a31ENhcXA5PDIhSyCCat5fdymHjMzA34JrHD3H8Qs6upeFfOA68OjGM4AdrV1U/sLd7/N3Ue7+3iC/fi8u/8j8GfgqrBa/Da3fRZXhfX71S9Id98CbDSzY8OiC4C3GMD7mWDY6AwzGxT+O2/b5gG7n2Mc7H5dAFxsZkVhD+visOzA9PWkSh9O5lwCrCa4p8Ptfd2eXtqmswm6icuAv4d/lxCMpT4HrAn/OzSsbwRHYa0F3iA4sqPPt6MH238u8GT4+GjgNYL7djwKZIflOeHzinD50X3d7kPc1pOB8nBf/wEoGuj7GbgTWAm8CTwIZA+0/Qz8jmDOpIngF/+Nh7JfgY+H214B3HAwbdBlLkREpF1Uh49ERCQJhYKIiLRTKIiISDuFgoiItFMoiIhIO4WCiIi0UyiIiEi7/w/Y8RV46BnyTQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def q_learning(env, num_episodes, discount_factor=1.0, alpha=0.5, epsilon=0.1, Q=None):\n",
    "    \"\"\"\n",
    "    Q-Learning algorithm: Off-policy TD control. Finds the optimal greedy policy\n",
    "    while following an epsilon-greedy policy\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        env: OpenAI environment.\n",
    "        num_episodes: Number of episodes to run for.\n",
    "        discount_factor: Gamma discount factor.\n",
    "        alpha: TD learning rate.\n",
    "        epsilon: Probability to sample a random action. Float between 0 and 1.\n",
    "        Q: hot-start the algorithm with a Q value function (optional)\n",
    "    \n",
    "    Returns:\n",
    "        A tuple (Q, stats).\n",
    "        Q is the optimal action-value function, a dictionary mapping state -> action values.\n",
    "        stats is a list of tuples giving the episode lengths and rewards.\n",
    "    \"\"\"\n",
    "    \n",
    "    # The final action-value function.\n",
    "    # A nested dictionary that maps state -> (action -> action-value).\n",
    "    if Q is None:\n",
    "        Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "    \n",
    "    # Keeps track of useful statistics\n",
    "    stats = []\n",
    "    \n",
    "    # The policy we're following\n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, env.action_space.n)\n",
    "    \n",
    "\n",
    "    for i_episode in tqdm(range(num_episodes)):\n",
    "        i = 0\n",
    "        R = 0\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            a = policy(s)\n",
    "            observation,reward,done,info = env.step(a)\n",
    "            \n",
    "            a_prime = np.argmax(Q[observation])\n",
    "            current_Q = Q[s][a]\n",
    "            \n",
    "            Q[s][a] = current_Q + alpha * (reward + discount_factor * Q[observation][a_prime] - current_Q)\n",
    "            \n",
    "            s = observation\n",
    "            \n",
    "            R += reward\n",
    "            i += 1\n",
    "        \n",
    "        stats.append((i, R))\n",
    "    episode_lengths, episode_returns = zip(*stats)\n",
    "    return Q, (episode_lengths, episode_returns)\n",
    "\n",
    "Q_q_learning, (episode_lengths_q_learning, episode_returns_q_learning) = q_learning(env, 1000)\n",
    "\n",
    "# We will help you with plotting this time\n",
    "plt.plot(episode_lengths_q_learning)\n",
    "plt.title('Episode lengths Q-learning')\n",
    "plt.show()\n",
    "plt.plot(episode_returns_q_learning)\n",
    "plt.title('Episode returns Q-learning')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f695c6e9d66afd4fc7a49b565419ba5d",
     "grade": false,
     "grade_id": "cell-9f1fcee44ba712c2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now compare the episode returns while learning for Q-learning and Sarsa (maybe run some more iterations?), by plotting the returns for both algorithms in a single plot, like in the book, Example 6.6. In order to be able to compare them, you may want to zoom in on the y-axis and smooth the returns (e.g. plotting the $n$ episode average instead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3c1a110fe85c38220afed145a8cf09bc",
     "grade": true,
     "grade_id": "cell-69ed62a52a44dd78",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:02<00:00, 4568.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:02<00:00, 4720.09it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "nE = 10000\n",
    "step_size = 100\n",
    "\n",
    "#Sarsa\n",
    "Q_sarsa, (episode_lengths_sarsa, episode_returns_sarsa) = sarsa(env, nE)\n",
    "\n",
    "#Q-Learning\n",
    "Q_q_learning, (episode_lengths_q_learning, episode_returns_q_learning) = q_learning(env, nE)\n",
    "\n",
    "#Plot\n",
    "#plt.plot(episode_returns_sarsa,label=\"Sarsa\")\n",
    "#plt.plot(episode_returns_q_learning, label= \"Q-learning\")\n",
    "\n",
    "x = list(range(0,nE+step_size,step_size))\n",
    "#y = episode_returns_sarsa\n",
    "mean_sarsa = [sum(episode_returns_sarsa[x[i]:x[i+1]]) / step_size for i in range( len(x) - 1)]\n",
    "mean_q_learning = [sum(episode_returns_q_learning[x[i]:x[i+1]]) / step_size for i in range( len(x) - 1)]\n",
    "\n",
    "plt.plot(x,[episode_returns_sarsa[0]] + mean_sarsa,label=\"Sarsa\")\n",
    "plt.plot(x,[episode_returns_q_learning[0]] + mean_q_learning, label= \"Q-learning\")    \n",
    "\n",
    "plt.title('Smoothed Episode returns of window ' + str(step_size),fontweight=\"bold\",fontsize=15)\n",
    "plt.ylim(top=-15,bottom=-30)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ed2526b0c0f17f055f520f67072c59ac",
     "grade": false,
     "grade_id": "cell-7ef9de74c57a4f0c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Which algorithm achieves higher return during learning? How does this compare to Example 6.6 from the book? Try to explain your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a3357293c326223f2a02cae0f38ca24a",
     "grade": true,
     "grade_id": "cell-7acf9de8c94a171f",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "#### Answer: \n",
    "Q-learning achieves a more higher and consistent return during learning compared to Sarsa in the plot above. While in example 6.6, Sarsa achieves a higher return than Q-learning, but this example differs from the Windy-gridworld one. \n",
    "\n",
    "The main differences are the absence of wind and having a cliff that results into a major negative reward of -100. This increase in negative reward value has a significant effect on the updates of the two methods. For Q-learning, the target policy update is a greedy one, and thus will find the optimal path as it succeeds a few times to reach the goal. This optimal path is along the cliff, but since the behaviour policy is a epsilon-greedy policy one, it can still fall of the cliff and getting a reward of -100. This is a big negative reward and can be tracked back in the return of an episode as observed on 132 of the book. while Sarsa will update with epsilon greedy and take a safer path and minimizes the negative reward. \n",
    "\n",
    "In the Windy-Gridworld example, there is no huge negative reward as each step everywhere is a reward of -1. Making the updated Q-values with greedy policy find an optimal path without a heavy penalty that occur due to the behaviour policy. In addition, when updating Q-values with greedy policy can ensure for a better representation here. Because when one relies on a not so accuracte Q-value, it will not only go to a wrong place, it might also get pushed up by the wind, making it even harder to reach the goal. For this reason, the rewards of Sarsa are less consistent as it cannot handle the effect of the wind well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f2f954f745662334010f6fb0fcfd9896",
     "grade": false,
     "grade_id": "cell-316d3cfd35d55387",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "After we have learned the policy, we do not care about exploration any more and we may switch to a deterministic (greedy) policy instead. If we evaluate this for both Sarsa and Q-learning (actually, for Q-learning the learned policy is already deterministic), which policy would you expect to perform better? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "011f8038ac100bfdc5e40b78c1bdc2f8",
     "grade": true,
     "grade_id": "cell-ea5058e6f352d717",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "#### Answer: \n",
    "In this example, Q-learning is expected to perform better due to its greedy target policy update as supported by the plot above. For Sarsa, If epsilon reduces over time, then Sarsa will also converge to optimal Q-values as it becomes more greedy and becomes closer to Q-learning method. In the end, both will have found an optimal policy and thus will act similiarly. But if one has to pick, than probably Q-learning as it will converge (faster) and here epsilon for Sarsa does not decrease over time.\n",
    "\n",
    "After experimenting the two methods, which were used for many episodes, the results (15 steps) are the same for both as expected. This can be explained by the Q-values of Sarsa, which might have converged (or close enoguh) and thus acting on a greedy policy will result in the same actions. Furthermore, epsilon of 0.1 was used in training, which is already close to the greedy policy in Q-learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "57ab54058d433e24421d1e1224a9bc87",
     "grade": false,
     "grade_id": "cell-8bcc6f5839a36860",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Please run the experiments to test your hypothesis (print or plot your results). How many runs do you need to evaluate the policy? Note: without learning, the order of the episodes is not relevant so a normal `plt.plot` may not be the most appropriate choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "149c39efef43f1807d2b06e6bc50bf95",
     "grade": true,
     "grade_id": "cell-55f9d1767bb7c011",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:00<00:00, 7426.94it/s]\n",
      "  0%|                                                                                         | 0/5000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "#Here the amount of steps needed is related to the reward, as each step is reward of -1. \n",
    "#Thus we can use either of them as a measure\n",
    "\n",
    "num_episodes = 5000\n",
    "\n",
    "def test_method(env,given_Q,num_episodes):\n",
    "    \n",
    "    stats = []\n",
    "    \n",
    "    for i_episode in tqdm(range(num_episodes)):\n",
    "        i = 0\n",
    "        R = 0\n",
    "\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            a = np.argmax(given_Q[s])\n",
    "            observation,reward,done,info = env.step(a)\n",
    "\n",
    "            s = observation\n",
    "            R += reward\n",
    "            i += 1\n",
    "        \n",
    "        stats.append((i, R))\n",
    "    episode_lengths, episode_returns = zip(*stats)\n",
    "    \n",
    "    return (episode_lengths, episode_returns)\n",
    "\n",
    "(e_len_q_learning, e_returns_q_learning) = test_method(env,Q_q_learning,num_episodes)\n",
    "(e_len_sarsa, e_returns_sarsa) = test_method(env,Q_sarsa, num_episodes)\n",
    "\n",
    "mean_e_len_q_learning = sum(e_len_q_learning) / len(e_len_q_learning)\n",
    "mean_e_len_sarsa = sum(e_len_sarsa) / len(e_len_sarsa)\n",
    "\n",
    "mean_e_returns_q_learning = sum(e_returns_q_learning) / len(e_returns_q_learning)\n",
    "mean_e_returns_sarsa = sum(e_returns_sarsa) / len(e_returns_sarsa)\n",
    "\n",
    "print(\"Mean of episode lengths for Q-learning \",mean_e_len_q_learning)\n",
    "print(\"Mean of episode lengths for Sarsa \",mean_e_len_sarsa)\n",
    "print(\"\\n\")\n",
    "print(\"Mean of episode returns for Q-learning \",mean_e_returns_q_learning)\n",
    "print(\"Mean of episode returns for Sarsa \",mean_e_returns_sarsa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e70351edfa59760104962f08d541557b",
     "grade": false,
     "grade_id": "cell-fef7e20e54e6243b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## 2. Deep Q-Network (DQN) (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e27fe8f72a248bbcf1f7a21e5550e657",
     "grade": true,
     "grade_id": "cell-39519f4ab05eb2a1",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.envs.make(\"CartPole-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env is a TimeLimit wrapper around an env, so use env.env to look into the env (but otherwise you can forget about this)\n",
    "??env.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# The nice thing about the CARTPOLE is that it has very nice rendering functionality (if you are on a local environment). Let's have a look at an episode\n",
    "obs = env.reset()\n",
    "env.render()\n",
    "done = False\n",
    "while not done:\n",
    "    obs, reward, done, _ = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n",
    "env.close()  # Close the environment or you will have a lot of render screens soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "11a9c014ee5fbe790ce999428cc22658",
     "grade": false,
     "grade_id": "cell-2d83f70e62b99520",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Remember from the previous lab, that in order to optimize a policy we need to estimate the Q-values (e.g. estimate the *action* values). In the CartPole problem, our state is current position of the cart, the current velocity of the cart, the current (angular) position of the pole and the (angular) speed of the pole. As these are continuous variables, we have an infinite number of states (ignoring the fact that a digital computer can only represent finitely many states in finite memory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9692b7acb09d018d9f80ce95685b81d5",
     "grade": false,
     "grade_id": "cell-bf2ac21267daffbb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Can you think of a way in which we can still use a tabular approach? Why would this work and can you think of an example problem where this would not work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3ffce6fca4071a1b543186db1b74cc98",
     "grade": true,
     "grade_id": "cell-b0fa2cb0c2cd2a63",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "#### Answer: \n",
    "As in lecture 5 with Gradient MC example, we can use a value to represent a specific group of range. In our Cartpole case, it seems obvious that when the position of a cart, or the angular postion of the pole exceeds a certain threshold for example, that one would always choose a certain action to balance it again. Thus to make it finite and the use of a tabular approach, we can assign values to a certain bin with 1 representative value. This can work as values above or below a certain threshold would always require the same action, making them redundant and reducing the amount of values needed to choose a certain action.\n",
    "Other cases where this would not work is where actions must be chosen based on more precion, reducing the range of bins and making their use trivial as it becomes a continous case again with infinite possible values to store. Examples of tasks requiring a lot of precision are like surgery or filling and dispensing medical prescriptions. These tasks could have a big effect on people and thus already have a bigger weight to the taken actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2c5bddd080e12cb076c845d093a70ed7",
     "grade": false,
     "grade_id": "cell-0b3162496f5e6cf5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.1 Implement Q-Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "84b9c38718c952ef8e62486fc9bf5e4a",
     "grade": false,
     "grade_id": "cell-96a86bcfa1ebc84a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We will not use the tabular approach but approximate the Q-value function by a general approximator function. We will skip the linear case and directly use a two layer Neural Network. We use [PyTorch](https://pytorch.org/) to implement the network, as this will allow us to train it easily later. We can implement a model using `torch.nn.Sequential`, but with PyTorch it is actually very easy to implement the model (e.g. the forward pass) from scratch. Now implement the `QNetwork.forward` function that uses one hidden layer with ReLU activation (no output activation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4ef7d14363dc2aa4beb638856c57a58c",
     "grade": false,
     "grade_id": "cell-216429a5dccf8a0e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_hidden=128):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = nn.Linear(4, num_hidden)\n",
    "        self.l2 = nn.Linear(num_hidden, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.Tensor(x)\n",
    "        \n",
    "        forward_pass = nn.Sequential(\n",
    "            self.l1,\n",
    "            nn.ReLU(),\n",
    "            self.l2\n",
    "        )\n",
    "        \n",
    "        return forward_pass(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2b9a48f9aee9ebc46da01c6f11cd789a",
     "grade": true,
     "grade_id": "cell-00ce108d640a5942",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's instantiate and test if it works\n",
    "num_hidden = 128\n",
    "torch.manual_seed(1234)\n",
    "model = QNetwork(num_hidden)\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "test_model = nn.Sequential(\n",
    "    nn.Linear(4, num_hidden), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(num_hidden, 2)\n",
    ")\n",
    "\n",
    "x = torch.rand(10, 4)\n",
    "\n",
    "# If you do not need backpropagation, wrap the computation in the torch.no_grad() context\n",
    "# This saves time and memory, and PyTorch complaints when converting to numpy\n",
    "with torch.no_grad():\n",
    "    assert np.allclose(model(x).numpy(), test_model(x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c7227d52671b410864319222a98e27d1",
     "grade": false,
     "grade_id": "cell-ca77eae2e62180cf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.2 Experience Replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5b3265bef151a12fe6969c378af76be2",
     "grade": false,
     "grade_id": "cell-b5b012e42dd2029e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "What could be a problem with doing gradient updates on a sequence of state, action pairs $((s_t, a_t), (s_{t+1}, a_{t+1}) ...)$ observed while interacting with the environment? How will using *experience replay* help to overcome this (potential problem)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "75e1a8b00b2bfa9b7dd8805b371c6a4e",
     "grade": true,
     "grade_id": "cell-70a2e59541668a25",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Next to the fact that transition can only occur once, subsequent transitions are highly correlated with each other. With experience replay, we can break this correlation as we use stored experiences from buffers. Then the network will also not overfit to the most recent experience. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9b3bbd8aaf3aade515736d0d07917a61",
     "grade": false,
     "grade_id": "cell-2c1d117a1a75fd69",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now implement the `push` function that adds a transition to the replay buffer, and the sample function that returns a batch of samples. It should keep at most the maximum number of transitions. Also implement the `sample` function that samples a (random!) batch of data, for use during training (hint: you can use the function `random.sample`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c64677cbc7efad32a949783b7c9b53b7",
     "grade": false,
     "grade_id": "cell-a3cc876e51eb157f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "\n",
    "    def push(self, transition):\n",
    "        \n",
    "        if len(self.memory) == self.capacity:\n",
    "            self.memory = self.memory[1:]   \n",
    "        \n",
    "        self.memory.append(transition)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory,batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6865749b3a8810bdaaf1604a9cea42e7",
     "grade": true,
     "grade_id": "cell-3b90135921c4da76",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "capacity = 10\n",
    "memory = ReplayMemory(capacity)\n",
    "\n",
    "# Sample a transition\n",
    "s = env.reset()\n",
    "a = env.action_space.sample()\n",
    "s_next, r, done, _ = env.step(a)\n",
    "\n",
    "# Push a transition\n",
    "memory.push((s, a, r, s_next, done))\n",
    "\n",
    "# Sample a batch size of 1\n",
    "print(memory.sample(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "354743bd76d6ba43d95b5b177443a202",
     "grade": false,
     "grade_id": "cell-88f67e3c051da6a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.3 $\\epsilon$psilon greedy policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "61d26d0dec0133f2aa737ed4711d6e08",
     "grade": false,
     "grade_id": "cell-aa3c7d1b3000f697",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In order to learn a good policy, we need to explore quite a bit initially. As we start to learn a good policy, we want to decrease the exploration. As the amount of exploration using an $\\epsilon$-greedy policy is controlled by $\\epsilon$, we can define an 'exploration scheme' by writing $\\epsilon$ as a function of time. There are many possible schemes, but we will use a simple one: we will start with only exploring (so taking random actions) at iteration 0, and then in 1000 iterations linearly anneal $\\epsilon$ such that after 1000 iterations we take random (exploration) actions with 5\\% probability (forever, as you never know if the environment will change)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "270ab31d4bb29dc9a05223c16a4967a7",
     "grade": false,
     "grade_id": "cell-5789e7a792108576",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_epsilon(it):\n",
    "    # YOUR CODE HERE\n",
    "    epsilon = 1 - (min(it,1000) * 0.00095) #After 1000 iterations epsilon should be 0.05\n",
    "    \n",
    "    return epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b1a81dd07e1b7a98d2cd06ebc171ebdd",
     "grade": true,
     "grade_id": "cell-40e66db45e742b2e",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# So what's an easy way to check?\n",
    "plt.plot([get_epsilon(it) for it in range(5000)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "84685c23e4eb899d7fed3a87b7f8915e",
     "grade": false,
     "grade_id": "cell-a8b604c9998c6c3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now write a function that takes a state and uses the Q-network to select an ($\\epsilon$-greedy) action. It should return a random action with probability epsilon (which we will pass later). Note, you do not need to backpropagate through the model computations, so use `with torch.no_grad():` (see above for example). Unlike numpy, PyTorch has no argmax function, but Google is your friend... Note that to convert a PyTorch tensor with only 1 element (0 dimensional) to a simple python scalar (int or float), you can use the '.item()' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "882f51819100c850120e73340aec387d",
     "grade": false,
     "grade_id": "cell-878ad3a637cfb51c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def select_action(model, state, epsilon):\n",
    "    # YOUR CODE HERE\n",
    "    with torch.no_grad():\n",
    "        Q_approx = model(state)\n",
    "        a = int(np.random.rand() * 2) if np.random.rand() < epsilon else torch.argmax(Q_approx).item()\n",
    "        \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "21f939075cb0c8dde152dabf47568a9d",
     "grade": true,
     "grade_id": "cell-e895338d56bee477",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "s = env.reset()\n",
    "a = select_action(model, s, 0.05)\n",
    "assert not torch.is_tensor(a)\n",
    "print (a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e66ac58d65710439ddf7cdf19a50cd8c",
     "grade": false,
     "grade_id": "cell-ec5e94e0b03f8aec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.4 Training function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4839aac72a80552046ebecc40c1615cf",
     "grade": false,
     "grade_id": "cell-d1a12cc97386fe56",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now we will implement the function 'train' that samples a batch from the memory and performs a gradient step using some convenient PyTorch functionality. However, you still need to compute the Q-values for the (state, action) pairs in the experience, as well as their target (e.g. the value they should move towards). What is the target for a Q-learning update? What should be the target if `next_state` is terminal (e.g. `done`)?\n",
    "\n",
    "For computing the Q-values for the actions, note that the model returns all action values where you are only interested in a single action value. Because of the batch dimension, you can't use simple indexing, but you may want to have a look at [torch.gather](https://pytorch.org/docs/stable/torch.html?highlight=gather#torch.gather) or use [advanced indexing](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html) (numpy tutorial but works mostly the same in PyTorch). Note, you should NOT modify the function train. You can view the size of a tensor `x` with `x.size()` (similar to `x.shape` in numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c466ee49add35cb1ec6a3e4a85f733c9",
     "grade": false,
     "grade_id": "cell-6c45485324b40081",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_q_val(model, state, action):\n",
    "    # YOUR CODE HERE\n",
    "    Q_approx = model(state)\n",
    "    action_values = torch.gather(Q_approx, dim=1, index=action.reshape(-1,1))\n",
    "    \n",
    "    return action_values\n",
    "    \n",
    "def compute_target(model, reward, next_state, done, discount_factor):\n",
    "    # done is a boolean (vector) that indicates if next_state is terminal (episode is done)\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    Q_approx = model(next_state)\n",
    "    max_Q = torch.max(Q_approx,dim=1)[0]\n",
    "    target = reward + discount_factor * max_Q\n",
    "\n",
    "    indices = torch.tensor(np.where(done),dtype=torch.long)\n",
    "    target = target.scatter(0, indices.reshape(-1), 0)\n",
    "    target = target.reshape(-1,1)\n",
    "        \n",
    "    return target\n",
    "\n",
    "def train(model, memory, optimizer, batch_size, discount_factor):\n",
    "    # DO NOT MODIFY THIS FUNCTION\n",
    "    \n",
    "    # don't learn without some decent experience\n",
    "    if len(memory) < batch_size:\n",
    "        return None\n",
    "\n",
    "    # random transition batch is taken from experience replay memory\n",
    "    transitions = memory.sample(batch_size)\n",
    "    \n",
    "    # transition is a list of 4-tuples, instead we want 4 vectors (as torch.Tensor's)\n",
    "    state, action, reward, next_state, done = zip(*transitions)\n",
    "    \n",
    "    # convert to PyTorch and define types\n",
    "    state = torch.tensor(state, dtype=torch.float)\n",
    "    action = torch.tensor(action, dtype=torch.int64)  # Need 64 bit to use them as index\n",
    "    next_state = torch.tensor(next_state, dtype=torch.float)\n",
    "    reward = torch.tensor(reward, dtype=torch.float)\n",
    "    done = torch.tensor(done, dtype=torch.uint8)  # Boolean\n",
    "    \n",
    "    # compute the q value\n",
    "    q_val = compute_q_val(model, state, action)\n",
    "    \n",
    "    with torch.no_grad():  # Don't compute gradient info for the target (semi-gradient)\n",
    "        target = compute_target(model, reward, next_state, done, discount_factor)\n",
    "    \n",
    "    # loss is measured from error between current and newly expected Q values\n",
    "    loss = F.smooth_l1_loss(q_val, target)\n",
    "\n",
    "    # backpropagation of loss to Neural Network (PyTorch magic)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()  # Returns a Python scalar, and releases history (similar to .detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "877c400001292b619e6871c1366524b9",
     "grade": true,
     "grade_id": "cell-b060b822eec4282f",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# You may want to test your functions individually, but after you do so lets see if the method train works.\n",
    "batch_size = 64\n",
    "discount_factor = 0.8\n",
    "learn_rate = 1e-3\n",
    "# Simple gradient descent may take long, so we will use Adam\n",
    "optimizer = optim.Adam(model.parameters(), learn_rate)\n",
    "\n",
    "# We need a larger memory, fill with dummy data\n",
    "transition = memory.sample(1)[0]\n",
    "memory = ReplayMemory(10 * batch_size)\n",
    "for i in range(batch_size):\n",
    "    memory.push(transition)\n",
    "\n",
    "# Now let's see if it works\n",
    "loss = train(model, memory, optimizer, batch_size, discount_factor)\n",
    "\n",
    "print (loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bd2841924b22cdf411348a0eb6080502",
     "grade": false,
     "grade_id": "cell-3eafd0ab49103f3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.5 Put it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "06dd71aae5c3c699f2b707b348a88107",
     "grade": false,
     "grade_id": "cell-36b8a04b393d8104",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now that you have implemented the training step, you should be able to put everything together. Implement the function `run_episodes` that runs a number of episodes of DQN training. It should return the durations (e.g. number of steps) of each episode. Note: we pass the train function as an argument such that we can swap it for a different training step later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c3f61b2ca270d84ab9b28d989dd65d4c",
     "grade": false,
     "grade_id": "cell-540a7d50ecc1d046",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def run_episodes(train, model, memory, env, num_episodes, batch_size, discount_factor, learn_rate):\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), learn_rate)\n",
    "    \n",
    "    global_steps = 0  # Count the steps (do not reset at episode start, to compute epsilon)\n",
    "    episode_durations = []  #\n",
    "    for i in range(num_episodes):\n",
    "        # YOUR CODE HERE\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        local_steps = 0\n",
    "        \n",
    "        while not done:\n",
    "            epsilon = get_epsilon(global_steps)\n",
    "            a = select_action(model, s, epsilon)\n",
    "            observation,reward,done,info = env.step(a)\n",
    "            \n",
    "            global_steps += 1\n",
    "            local_steps += 1\n",
    "\n",
    "            memory.push((s, a, reward, observation, done))\n",
    "            loss = train(model, memory, optimizer, batch_size, discount_factor)\n",
    "            \n",
    "            s = observation\n",
    "        \n",
    "        episode_durations.append(local_steps)\n",
    "        \n",
    "\n",
    "    return episode_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) #Added this seed for numpy, as used in selection action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run it!\n",
    "num_episodes = 100\n",
    "batch_size = 64\n",
    "discount_factor = 0.8\n",
    "learn_rate = 1e-3\n",
    "memory = ReplayMemory(10000)\n",
    "num_hidden = 128\n",
    "seed = 42  # This is not randomly chosen\n",
    "\n",
    "# We will seed the algorithm (before initializing QNetwork!) for reproducability\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "env.seed(seed)\n",
    "\n",
    "model = QNetwork(num_hidden)\n",
    "\n",
    "episode_durations = run_episodes(train, model, memory, env, num_episodes, batch_size, discount_factor, learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "70d16eb61eae34605e8d7813a70a604a",
     "grade": true,
     "grade_id": "cell-928ecc11ed5c43d8",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# And see the results\n",
    "def smooth(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "\n",
    "plt.plot(smooth(episode_durations, 10))\n",
    "plt.title('Episode durations per episode')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4f5e85e8aa15e9cb9117b17265435eae",
     "grade": false,
     "grade_id": "cell-6607b79e73a101a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "## 3. Policy Gradient (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "951b88e9cd8396d088d3f80e6da9690c",
     "grade": false,
     "grade_id": "cell-083fe71da94aa7aa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "So we have spent a lot of time working on *value based* methods. We will now switch to *policy based* methods, i.e. learn a policy directly rather than learn a value function from which the policy follows. Mention two advantages of using a policy based method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a5c1f505cb22eca6eb3b8213ff23e60f",
     "grade": true,
     "grade_id": "cell-134510705650d5ac",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "In policy based methods, there is an opportunity of using prior knowledge about the policy into the system, namely in the choice of the policy parameterization.\n",
    "\n",
    "In certain systems, the best approximate policy may be stochastic. Policy based methods enable action selection with arbitraty probabilities, in contrast to action-value methods, which have no natural way of finding stochastic optimal policies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "233ca94abc32f0e510c5d8a164206d05",
     "grade": false,
     "grade_id": "cell-76a10fe31897025f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 3.1 Policy Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2bc16b45e6145226b8a6f5117003b7f5",
     "grade": false,
     "grade_id": "cell-34f0712f792bbcca",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In order to do so, we will implement a Policy network. Although in general this does not have to be the case, we will use an architecture very similar to the Q-network (two layers with ReLU activation for the hidden layer). Since we have discrete actions, our model will output one value per action, where each value represents the (normalized!) log-probability of selecting that action. *Use the (log-)softmax activation function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "155baf230fd6deb5f6ccf93138fa3419",
     "grade": false,
     "grade_id": "cell-6a31440f9477f963",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_hidden=128):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = nn.Linear(4, num_hidden)\n",
    "        self.l2 = nn.Linear(num_hidden, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.l1(x)\n",
    "        a = F.relu(z)\n",
    "        out = self.l2(a)\n",
    "        pred = F.log_softmax(out.reshape((-1,2)), dim=1)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3cb94e04b03fa4b663bcf38a96ef656d",
     "grade": true,
     "grade_id": "cell-9d280fe6520edc91",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's instantiate and test if it works\n",
    "num_hidden = 128\n",
    "torch.manual_seed(1234)\n",
    "model = PolicyNetwork(num_hidden)\n",
    "\n",
    "x = torch.rand(10, 4)\n",
    "\n",
    "log_p = model(x)\n",
    "\n",
    "# Does the outcome make sense?\n",
    "print(log_p.exp())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8b0ff099a335c248a91df00e975494d0",
     "grade": false,
     "grade_id": "cell-35294ca4eda15b11",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 3.2 Monte Carlo REINFORCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "93ed9cbcf70541f5a04709ee89a16e78",
     "grade": false,
     "grade_id": "cell-44f33e587542974d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now we will implement the *Monte Carlo* policy gradient algorithm. Remember from lab 1 that this means that we will estimate returns for states by sample episodes. Compared to DQN, this means that we do *not* perform an update step at every environment step, but only at the end of each episode. This means that we should generate an episode of data, compute the REINFORCE loss (which requires computing the returns) and then perform a gradient step.\n",
    "\n",
    "To help you, we already implemented a few functions that you can (but do not have to) use.\n",
    "\n",
    "* You can use `torch.multinomial` to sample from a categorical distribution.\n",
    "* The REINFORCE loss is defined as $- \\sum_t \\log \\pi_\\theta(a_t|s_t) G_t$, which means that you should compute the (discounted) return $G_t$ for all $t$. Make sure that you do this in **linear time**, otherwise your algorithm will be very slow! Note the - (minus) since you want to maximize return while you want to minimize the loss.\n",
    "* Importantly, you should **normalize the returns** (not the rewards!, e.g. subtract mean and divide by standard deviation within the episode) before computing the loss, or your estimator will have very high variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3b2c75181678fed25fcc7c8b39bb7de3",
     "grade": true,
     "grade_id": "cell-3f6e32c4931392bf",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from statistics import mean, stdev\n",
    "\n",
    "def select_action(model, state):\n",
    "    # Samples an action according to the probability distribution induced by the model\n",
    "    # Also returns the log_probability\n",
    "    log_p = model(state)\n",
    "    action = torch.multinomial(log_p.exp(), 1).item()\n",
    "    log_p = log_p.reshape((2, -1))\n",
    "    \n",
    "    return action, log_p[action]\n",
    "\n",
    "def run_episode(env, model):\n",
    "    episode = []           \n",
    "    \n",
    "    s = env.reset()\n",
    "    action, logp = select_action(model, torch.Tensor(s))\n",
    "    observation,reward,done,info = env.step(action)\n",
    "    episode = [(logp, reward)]\n",
    "    \n",
    "    while not done:\n",
    "        action, logp = select_action(model, torch.Tensor(observation))\n",
    "        observation,reward,done,info = env.step(action)\n",
    "\n",
    "        episode.append((logp, reward))\n",
    "        \n",
    "    return episode\n",
    "\n",
    "def compute_reinforce_loss(episode, discount_factor):\n",
    "    # Compute the reinforce loss\n",
    "    # Make sure that your function runs in LINEAR TIME\n",
    "    # Don't forget to normalize your RETURNS (not rewards)\n",
    "    # Note that the rewards/returns should be maximized \n",
    "    # while the loss should be minimized so you need a - somewhere\n",
    "    \n",
    "    G = 0\n",
    "    Gs = [0 for i in range(len(episode))]\n",
    "    logs = [0 for i in range(len(episode))]\n",
    "    \n",
    "    for i in range(len(episode)-1,-1,-1):\n",
    "        logp ,reward = episode[i]\n",
    "        G = (discount_factor * G) + reward \n",
    "        Gs[i] = G\n",
    "        logs[i] = logp\n",
    "    \n",
    "    mu = mean(Gs)\n",
    "    sigma = stdev(Gs) \n",
    "    \n",
    "    loss = 0\n",
    "    for i in range(len(episode)-1,-1,-1):\n",
    "        loss += logs[i] * (Gs[i] - mu)/sigma\n",
    "    \n",
    "    return -loss\n",
    "\n",
    "def run_episodes_policy_gradient(model, env, num_episodes, discount_factor, learn_rate):\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), learn_rate)\n",
    "    \n",
    "    episode_durations = []\n",
    "    for i in range(num_episodes):\n",
    "        \n",
    "        episode = run_episode(env, model)\n",
    "        loss = compute_reinforce_loss(episode, discount_factor)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                           \n",
    "        if i % 10 == 0:\n",
    "            print(\"{2} Episode {0} finished after {1} steps\"\n",
    "                  .format(i, len(episode), '\\033[92m' if len(episode) >= 195 else '\\033[99m'))\n",
    "        episode_durations.append(len(episode))\n",
    "        \n",
    "    return episode_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to play around with the parameters!\n",
    "num_episodes = 200\n",
    "discount_factor = 0.99\n",
    "learn_rate = 0.01\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "env.seed(seed)\n",
    "\n",
    "model = PolicyNetwork(num_hidden)\n",
    "\n",
    "episode_durations_policy_gradient = run_episodes_policy_gradient(\n",
    "    model, env, num_episodes, discount_factor, learn_rate)\n",
    "\n",
    "plt.plot(smooth(episode_durations_policy_gradient, 10))\n",
    "plt.title('Episode durations per episode')\n",
    "plt.legend(['Policy gradient'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "454f1fb392b88af636d085896efb2aad",
     "grade": false,
     "grade_id": "cell-ad1138b69e6728a0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 4. Deep Reinforcement Learning (5 bonus points)\n",
    "Note that so far we used the state variables as input. However, the true power of Deep Learning is that we can directly learn from raw inputs, e.g. we can learn to balance the cart pole *by just looking at the screen*. This probably means that you need a deep(er) (convolutional) network, as well as tweaking some parameters, running for more iterations (perhaps on GPU) and do other tricks to stabilize learning. Can you get this to work? This will earn you bonus points!\n",
    "\n",
    "Hints:\n",
    "* You may want to use [Google Colab](https://colab.research.google.com/) such that you can benefit from GPU acceleration.\n",
    "* Even if you don't use Colab, save the weights of your final model and load it in the code here (see example below). Hand in the model file with the .ipynb in a .zip. We likely won't be able to run your training code during grading!\n",
    "* Preprocessing is already done for you, and the observation is the difference between two consequtive frames such that the model can 'see' (angular) speed from a single image. Now do you see why we (sometimes) use the word observation (and not state)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f660e1484fe2bf60d66467326eacb1ba",
     "grade": false,
     "grade_id": "cell-9c9dfa80827c5680",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "class CartPoleRawEnv(gym.Env):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self._env = gym.make('CartPole-v0', *args, **kwargs)  #.unwrapped\n",
    "        self.action_space = self._env.action_space\n",
    "        screen_height, screen_width = 40, 80  # TODO\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0, high=255, \n",
    "            shape=(screen_height, screen_width, 3), dtype=np.uint8)\n",
    "    \n",
    "    def seed(self, seed=None):\n",
    "        return self._env.seed(seed)\n",
    "    \n",
    "    def reset(self):\n",
    "        s = self._env.reset()\n",
    "        self.prev_screen = self.screen = self.get_screen()\n",
    "        return self._get_observation()\n",
    "    \n",
    "    def step(self, action):\n",
    "        s, r, done, info = self._env.step(action)\n",
    "        self.prev_screen = self.screen\n",
    "        self.screen = self.get_screen()\n",
    "        return self._get_observation(), r, done, info\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        return self.screen - self.prev_screen\n",
    "    \n",
    "    def _get_cart_location(self, screen_width):\n",
    "        _env = self._env.unwrapped\n",
    "        world_width = _env.x_threshold * 2\n",
    "        scale = screen_width / world_width\n",
    "        return int(_env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "    def get_screen(self):\n",
    "        screen = self._env.unwrapped.render(mode='rgb_array').transpose(\n",
    "            (2, 0, 1))  # transpose into torch order (CHW)\n",
    "        # Strip off the top and bottom of the screen\n",
    "        _, screen_height, screen_width = screen.shape\n",
    "        screen = screen[:, screen_height * 4 // 10:screen_height * 8 // 10]\n",
    "        view_width = screen_height * 8 // 10\n",
    "        cart_location = self._get_cart_location(screen_width)\n",
    "        if cart_location < view_width // 2:\n",
    "            slice_range = slice(view_width)\n",
    "        elif cart_location > (screen_width - view_width // 2):\n",
    "            slice_range = slice(-view_width, None)\n",
    "        else:\n",
    "            slice_range = slice(cart_location - view_width // 2,\n",
    "                                cart_location + view_width // 2)\n",
    "        # Strip off the edges, so that we have a square image centered on a cart\n",
    "        screen = screen[:, :, slice_range]\n",
    "        # Convert to float, rescare, convert to torch tensor\n",
    "        # (this doesn't require a copy)\n",
    "        screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "        screen = torch.from_numpy(screen)\n",
    "        # Resize, and add a batch dimension (BCHW)\n",
    "        #return screen.unsqueeze(0).to(device)\n",
    "        return resize(screen).unsqueeze(0)\n",
    "    \n",
    "    def close(self):\n",
    "        return self._env.close()\n",
    "\n",
    "raw_env = CartPoleRawEnv()\n",
    "s = raw_env.reset()\n",
    "\n",
    "# \n",
    "s, r, done, _ = raw_env.step(env.action_space.sample())\n",
    "\n",
    "raw_env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(raw_env.get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()\n",
    "\n",
    "# Observations are (-1, 1) while we need to plot (0, 1) so show (rgb + 1) / 2\n",
    "plt.figure()\n",
    "plt.imshow((s.cpu().squeeze(0).permute(1, 2, 0).numpy() + 1) / 2,\n",
    "           interpolation='none')\n",
    "plt.title('Example observation')\n",
    "plt.show()\n",
    "raw_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe you should make it a bit deeper?\n",
    "class DeepPolicy(nn.Module):\n",
    "    def __init__(self,device):\n",
    "        nn.Module.__init__(self)\n",
    "        #self.l1 = nn.Linear(40 * 80 * 3, 2)\n",
    "        self.device = device\n",
    "        #Alexnet implementation based, 4 conv layers\n",
    "        self.fc1 = nn.Linear(960,300)\n",
    "        self.fc2 = nn.Linear(300,300)\n",
    "        self.fc3 = nn.Linear(300,2)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.network = nn.Sequential(\n",
    "                                nn.Conv2d(3, out_channels = 40, kernel_size=11 , stride=2, padding=0),\n",
    "                                nn.ReLU(),\n",
    "                                #nn.LeakyReLU()\n",
    "                                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                                #nn.BatchNorm1d(),\n",
    "                                #nn.BatchNorm2d(40),\n",
    "                                nn.Conv2d(40, out_channels = 80, kernel_size=5 , stride=1, padding=2),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                                #nn.BatchNorm2d(80),\n",
    "                                nn.Conv2d(80, out_channels = 120, kernel_size=3 , stride=1, padding=2),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                                #nn.BatchNorm2d(120),\n",
    "                                nn.Conv2d(120, out_channels = 160, kernel_size=3 , stride=1, padding=2),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                               )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten\n",
    "        #return F.log_softmax(self.l1(x.view(x.size(0), -1)), -1)\n",
    "        x = x.to(self.device)\n",
    "        out = self.network(x)\n",
    "        out = out.view(out.shape[0],-1)\n",
    "        #out = self.drop(out)\n",
    "        out = self.fc1(out)\n",
    "        #out = self.relu(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.drop(out)\n",
    "        #out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        #out = self.relu(out)\n",
    "        \n",
    "        probs = F.log_softmax(out, -1)\n",
    "        \n",
    "        return probs\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"  \n",
    "print(device)\n",
    "policy = DeepPolicy(device)\n",
    "policy = policy.to(device)\n",
    "filename = 'weights.pt'\n",
    "\n",
    "if os.path.isfile(filename):\n",
    "    print(f\"Loading weights from {filename}\")\n",
    "    weights = torch.load(filename, map_location='cpu')\n",
    "    \n",
    "    policy.load_state_dict(weights['policy'])\n",
    "    \n",
    "else:\n",
    "    # Train\n",
    "    \n",
    "    ### TODO some training here, maybe? Or run this on a different machine?\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    learn_rate = 0.0001\n",
    "    \n",
    "    #REINFORCE from before\n",
    "    optimizer = optim.Adam(policy.parameters(), learn_rate)\n",
    "    \n",
    "    global_steps = 0  # Count the steps (do not reset at episode start, to compute epsilon)\n",
    "    episode_durations = []  \n",
    "    \n",
    "    for i in range(1500):\n",
    "        \n",
    "        s = raw_env.reset()\n",
    "        \n",
    "        episode = run_episode(raw_env, policy)\n",
    "        raw_env.close()\n",
    "        loss = compute_reinforce_loss(episode, discount_factor)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"{2} Episode {0} finished after {1} steps\"\n",
    "                  .format(i, len(episode), '\\033[92m' if len(episode) >= 195 else '\\033[99m'))\n",
    "        episode_durations.append(len(episode))\n",
    "    \n",
    "    print(f\"Saving weights to {filename}\")\n",
    "    torch.save({\n",
    "        # You can add more here if you need, e.g. critic\n",
    "        'policy': policy.state_dict()  # Always save weights rather than objects\n",
    "    },\n",
    "    \"weights.pt\")\n",
    "    \n",
    "def bonus_get_action(x):\n",
    "    return policy(x).exp().multinomial(1)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(smooth(episode_durations, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4502e425cdd9d5db2ec0e9e8e972fa0b",
     "grade": true,
     "grade_id": "cell-0d7bd58a23fdfabb",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "episode_durations = []\n",
    "for i in range(20):  # Not too many since it may take forever to render\n",
    "    test_env = CartPoleRawEnv()\n",
    "    test_env.seed(seed + i)\n",
    "    state = test_env.reset()\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "        steps += 1\n",
    "        with torch.no_grad():\n",
    "            action = bonus_get_action(state).item()\n",
    "        state, reward, done, _ = test_env.step(action)\n",
    "    episode_durations.append(steps)\n",
    "    test_env.close()\n",
    "    \n",
    "plt.plot(episode_durations)\n",
    "plt.title('Episode durations')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
