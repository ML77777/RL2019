{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from tqdm import tqdm as _tqdm\n",
    "\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "\n",
    "def tqdm(*args, **kwargs):\n",
    "    return _tqdm(*args, **kwargs, mininterval=1)  # Safety, do not overflow buffer\n",
    "\n",
    "EPS = float(np.finfo(np.float32).eps)\n",
    "\n",
    "assert sys.version_info[:3] >= (3, 6, 0), \"Make sure you have Python 3.6 installed!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marvi\\Anaconda3\\envs\\rl2019\\lib\\site-packages\\gym\\envs\\registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\n",
      "WARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env_cartpole = gym.envs.make(\"CartPole-v0\") # Has two actions, See doc for mor info, ??env_cartpole.env\n",
    "env_car = gym.envs.make(\"MountainCar-v0\")   # Has three actions\n",
    "env_pen = gym.envs.make(\"Pendulum-v0\")      # Has continious action values like array([-1.2552279] or array([1.7774895] \n",
    "env_acrobot = gym.envs.make(\"Acrobot-v1\")   # Has Three actions, applying +1, 0 or -1 torque on the joint between #\n",
    "                                            # the two pendulum links.   See doc for more info, ??env_acrobot.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#??env_acrobot.env\n",
    "#env_acrobot.action_space.sample()\n",
    "#env = env_cartpole\n",
    "env = env_car\n",
    "#env = env_acrobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"  \n",
    "device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test demo environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# The nice thing about the CARTPOLE is that it has very nice rendering functionality (if you are on a local environment). Let's have a look at an episode\n",
    "obs = env.reset()\n",
    "env.render()\n",
    "done = False\n",
    "while not done:\n",
    "    obs, reward, done, _ = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n",
    "env.close()  # Close the environment or you will have a lot of render screens soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our DQN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, device,num_input=4,num_hidden=128,num_output=2):\n",
    "        nn.Module.__init__(self)\n",
    "        self.device = device\n",
    "        self.l1 = nn.Linear(num_input, num_hidden)\n",
    "        self.l2 = nn.Linear(num_hidden, num_output)\n",
    "        self.input_dim = num_input\n",
    "        self.hidden_dim = num_hidden\n",
    "        self.output_dim = num_output\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.Tensor(x)\n",
    "            \n",
    "        x = x.to(self.device)\n",
    "        \n",
    "        forward_pass = nn.Sequential(\n",
    "            self.l1,\n",
    "            nn.ReLU(),\n",
    "            self.l2\n",
    "        )\n",
    "        \n",
    "        return forward_pass(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epsilon ($\\epsilon$) greedy policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epsilon(it):\n",
    "    # YOUR CODE HERE\n",
    "    epsilon = 1 - (min(it,1000) * 0.00095) #After 1000 iterations epsilon should be 0.05\n",
    "    \n",
    "    return epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_schedule(it,max_iter,initial_value,final_value):\n",
    "    #Following general formula of get epislon\n",
    "    parameter_value = initial_value - (min(it,max_iter) * ( (initial_value - final_value) / max_iter) )\n",
    "                            \n",
    "    return parameter_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(model, state, epsilon):\n",
    "    # YOUR CODE HERE\n",
    "    with torch.no_grad():\n",
    "        Q_approx = model(state)\n",
    "        a = int(np.random.rand() * model.output_dim) if np.random.rand() < epsilon else torch.argmax(Q_approx).item()\n",
    "        \n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience replays types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.name = \"uniform\"\n",
    "\n",
    "    def push(self, transition):\n",
    "        \n",
    "        if len(self.memory) == self.capacity:\n",
    "            self.memory = self.memory[1:]   \n",
    "        \n",
    "        self.memory.append(transition)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory,batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prioritized Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_tree import SumSegmentTree, MinSegmentTree\n",
    "\n",
    "#Source OpenAI: https://github.com/openai/baselines/blob/master/baselines/deepq/replay_buffer.py\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, size):\n",
    "        \"\"\"Create Replay buffer.\n",
    "        Parameters\n",
    "        ----------\n",
    "        size: int\n",
    "            Max number of transitions to store in the buffer. When the buffer\n",
    "            overflows the old memories are dropped.\n",
    "        \"\"\"\n",
    "        self._storage = []\n",
    "        self._maxsize = size\n",
    "        self._next_idx = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._storage)\n",
    "\n",
    "    def add(self, obs_t, action, reward, obs_tp1, done):\n",
    "        data = (obs_t, action, reward, obs_tp1, done)\n",
    "\n",
    "        if self._next_idx >= len(self._storage):\n",
    "            self._storage.append(data)\n",
    "        else:\n",
    "            self._storage[self._next_idx] = data\n",
    "        self._next_idx = (self._next_idx + 1) % self._maxsize\n",
    "\n",
    "    def _encode_sample(self, idxes):\n",
    "        obses_t, actions, rewards, obses_tp1, dones = [], [], [], [], []\n",
    "        for i in idxes:\n",
    "            data = self._storage[i]\n",
    "            obs_t, action, reward, obs_tp1, done = data\n",
    "            obses_t.append(np.array(obs_t, copy=False))\n",
    "            actions.append(np.array(action, copy=False))\n",
    "            rewards.append(reward)\n",
    "            obses_tp1.append(np.array(obs_tp1, copy=False))\n",
    "            dones.append(done)\n",
    "        return np.array(obses_t), np.array(actions), np.array(rewards), np.array(obses_tp1), np.array(dones)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Sample a batch of experiences.\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size: int\n",
    "            How many transitions to sample.\n",
    "        Returns\n",
    "        -------\n",
    "        obs_batch: np.array\n",
    "            batch of observations\n",
    "        act_batch: np.array\n",
    "            batch of actions executed given obs_batch\n",
    "        rew_batch: np.array\n",
    "            rewards received as results of executing act_batch\n",
    "        next_obs_batch: np.array\n",
    "            next set of observations seen after executing act_batch\n",
    "        done_mask: np.array\n",
    "            done_mask[i] = 1 if executing act_batch[i] resulted in\n",
    "            the end of an episode and 0 otherwise.\n",
    "        \"\"\"\n",
    "        idxes = [random.randint(0, len(self._storage) - 1) for _ in range(batch_size)]\n",
    "        return self._encode_sample(idxes)\n",
    "\n",
    "\n",
    "class PrioritizedReplayBuffer(ReplayBuffer):\n",
    "    def __init__(self, size, alpha):\n",
    "        \"\"\"Create Prioritized Replay buffer.\n",
    "        Parameters\n",
    "        ----------\n",
    "        size: int\n",
    "            Max number of transitions to store in the buffer. When the buffer\n",
    "            overflows the old memories are dropped.\n",
    "        alpha: float\n",
    "            how much prioritization is used\n",
    "            (0 - no prioritization, 1 - full prioritization)\n",
    "        See Also\n",
    "        --------\n",
    "        ReplayBuffer.__init__\n",
    "        \"\"\"\n",
    "        super(PrioritizedReplayBuffer, self).__init__(size)\n",
    "        assert alpha >= 0\n",
    "        self._alpha = alpha\n",
    "\n",
    "        it_capacity = 1\n",
    "        while it_capacity < size:\n",
    "            it_capacity *= 2\n",
    "\n",
    "        self._it_sum = SumSegmentTree(it_capacity)\n",
    "        self._it_min = MinSegmentTree(it_capacity)\n",
    "        self._max_priority = 1.0\n",
    "        self.name = \"prioritized\"\n",
    "\n",
    "    def add(self, *args, **kwargs):\n",
    "        \"\"\"See ReplayBuffer.store_effect\"\"\"\n",
    "        idx = self._next_idx\n",
    "        super().add(*args, **kwargs)\n",
    "        self._it_sum[idx] = self._max_priority ** self._alpha\n",
    "        self._it_min[idx] = self._max_priority ** self._alpha\n",
    "\n",
    "    def _sample_proportional(self, batch_size):\n",
    "        res = []\n",
    "        p_total = self._it_sum.sum(0, len(self._storage) - 1)\n",
    "        every_range_len = p_total / batch_size\n",
    "        for i in range(batch_size):\n",
    "            mass = random.random() * every_range_len + i * every_range_len\n",
    "            idx = self._it_sum.find_prefixsum_idx(mass)\n",
    "            res.append(idx)\n",
    "        return res\n",
    "\n",
    "    def sample(self, batch_size, beta):\n",
    "        \"\"\"Sample a batch of experiences.\n",
    "        compared to ReplayBuffer.sample\n",
    "        it also returns importance weights and idxes\n",
    "        of sampled experiences.\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size: int\n",
    "            How many transitions to sample.\n",
    "        beta: float\n",
    "            To what degree to use importance weights\n",
    "            (0 - no corrections, 1 - full correction)\n",
    "        Returns\n",
    "        -------\n",
    "        obs_batch: np.array\n",
    "            batch of observations\n",
    "        act_batch: np.array\n",
    "            batch of actions executed given obs_batch\n",
    "        rew_batch: np.array\n",
    "            rewards received as results of executing act_batch\n",
    "        next_obs_batch: np.array\n",
    "            next set of observations seen after executing act_batch\n",
    "        done_mask: np.array\n",
    "            done_mask[i] = 1 if executing act_batch[i] resulted in\n",
    "            the end of an episode and 0 otherwise.\n",
    "        weights: np.array\n",
    "            Array of shape (batch_size,) and dtype np.float32\n",
    "            denoting importance weight of each sampled transition\n",
    "        idxes: np.array\n",
    "            Array of shape (batch_size,) and dtype np.int32\n",
    "            idexes in buffer of sampled experiences\n",
    "        \"\"\"\n",
    "        assert beta > 0\n",
    "\n",
    "        idxes = self._sample_proportional(batch_size)\n",
    "\n",
    "        weights = []\n",
    "        p_min = self._it_min.min() / self._it_sum.sum()\n",
    "        max_weight = (p_min * len(self._storage)) ** (-beta)\n",
    "\n",
    "        for idx in idxes:\n",
    "            p_sample = self._it_sum[idx] / self._it_sum.sum()\n",
    "            weight = (p_sample * len(self._storage)) ** (-beta)\n",
    "            weights.append(weight / max_weight)\n",
    "        weights = np.array(weights)\n",
    "        encoded_sample = self._encode_sample(idxes)\n",
    "        return tuple(list(encoded_sample) + [weights, idxes])\n",
    "\n",
    "    def update_priorities(self, idxes, priorities):\n",
    "        \"\"\"Update priorities of sampled transitions.\n",
    "        sets priority of transition at index idxes[i] in buffer\n",
    "        to priorities[i].\n",
    "        Parameters\n",
    "        ----------\n",
    "        idxes: [int]\n",
    "            List of idxes of sampled transitions\n",
    "        priorities: [float]\n",
    "            List of updated priorities corresponding to\n",
    "            transitions at the sampled idxes denoted by\n",
    "            variable `idxes`.\n",
    "        \"\"\"\n",
    "        assert len(idxes) == len(priorities)\n",
    "        for idx, priority in zip(idxes, priorities):\n",
    "            assert priority > 0\n",
    "            assert 0 <= idx < len(self._storage)\n",
    "            self._it_sum[idx] = priority ** self._alpha\n",
    "            self._it_min[idx] = priority ** self._alpha\n",
    "\n",
    "            self._max_priority = max(self._max_priority, priority)\n",
    "            \n",
    "def train_prioritized(model, memory, optimizer, batch_size, discount_factor,beta,prioritized_replay_eps=1e-6):\n",
    "    # DO NOT MODIFY THIS FUNCTION\n",
    "    \n",
    "    # don't learn without some decent experience\n",
    "    if len(memory) < batch_size:\n",
    "        return None\n",
    "\n",
    "    # random transition batch is taken from experience replay memory\n",
    "    #----------------------------#Adjusted of normal train--------------------------------------------------------\n",
    "    transitions = memory.sample(batch_size, beta=beta)\n",
    "    (state, action, reward, next_state, done, weights, batch_idxes) = transitions#zip(*transitions)\n",
    "    \n",
    "    # convert to PyTorch and define types\n",
    "    state = torch.tensor(state, dtype=torch.float, device = model.device)\n",
    "    action = torch.tensor(action, dtype=torch.int64, device = model.device)  # Need 64 bit to use them as index\n",
    "    next_state = torch.tensor(next_state, dtype=torch.float, device = model.device)\n",
    "    reward = torch.tensor(reward, dtype=torch.float, device = model.device)\n",
    "    done = torch.tensor(done, dtype=torch.uint8)  # Boolean\n",
    "    weights = torch.tensor(weights, dtype=torch.float, device = model.device)\n",
    "    #batch_idxes = torch.tensor(batch_idxes, dtype = torch.int64, device = model.device)\n",
    "    \n",
    "     #-------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # compute the q value\n",
    "    q_val = compute_q_val(model, state, action)\n",
    "    \n",
    "    with torch.no_grad():  # Don't compute gradient info for the target (semi-gradient)\n",
    "        target = compute_target(model, reward, next_state, done, discount_factor)\n",
    "    \n",
    "    # loss is measured from error between current and newly expected Q values\n",
    "    loss = F.smooth_l1_loss(q_val, target)\n",
    "    \n",
    "    # backpropagation of loss to Neural Network (PyTorch magic)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    mean_loss_value = loss.item() \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        td_errors = F.smooth_l1_loss(q_val, target,reduction=\"none\") #TD errors, \n",
    "    #td_errors = train(obses_t, actions, rewards, obses_tp1, dones, weights)\n",
    "        if model.device == \"cpu\":\n",
    "            td_errors = td_errors.detach().numpy()\n",
    "        else:\n",
    "            td_errors = td_errors.cpu().detach().numpy()\n",
    "    new_priorities = np.abs(td_errors) + prioritized_replay_eps\n",
    "    #new_priorities = np.abs(loss_value) + prioritized_replay_eps\n",
    "    memory.update_priorities(batch_idxes, new_priorities)\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    return mean_loss_value  # Returns a Python scalar, and releases history (similar to .detach())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selective Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectiveReplayMemory:\n",
    "    \n",
    "    def __init__(self, fifo_capacity, episodic_memory_capacity):\n",
    "        self.fifo_capacity = fifo_capacity\n",
    "        self.episodic_capacity = episodic_memory_capacity\n",
    "        self.fifo_memory = []\n",
    "        self.episodic_memory = []\n",
    "        self.name = \"selective\"\n",
    "\n",
    "    def push(self, transition):\n",
    "        \n",
    "        if len(self.fifo_memory) == self.fifo_capacity:\n",
    "            self.fifo_memory = self.fifo_memory[1:]   \n",
    "        \n",
    "        self.fifo_memory.append(transition)\n",
    "    \n",
    "        #Distribution matching selection\n",
    "        rank_value = np.random.standard_normal(1)\n",
    "        self.episodic_memory.append( (transition,rank_value) )\n",
    "        \n",
    "        if len(self.episodic_memory) > self.episodic_capacity:\n",
    "            sorted_episodic = sorted(self.episodic_memory, key=operator.itemgetter(1))\n",
    "            self.episodic_memory = sorted_episodic[1:]    #Smallest value is index 0 to be removed\n",
    "        \n",
    "        #Since no dictionairy was/could be used, duplicate states can be present in the episodic memory\n",
    "        #Or else could use dictionairy of state to rank value and dict state to other details of transition.\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \n",
    "        #50% chance to sample from either buffer?\n",
    "        #samples = random.sample(self.memory,batch_size)\n",
    "        #samples = random.sample(self.episodic_memory.keys(),batch_size)\n",
    "        \n",
    "        #Or concatenate and sample\n",
    "        concat = self.fifo_memory + [i[0] for i in self.episodic_memory]\n",
    "        samples = random.sample(concat,batch_size)\n",
    "        \n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fifo_memory) #+ len(episodic_memory) #Do we count both memories as len? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hindsight Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Epsilon_Greedy_Goal(nn.Module):\n",
    "    \n",
    "    def __init__(self,device,num_input,num_hidden,num_output):\n",
    "        nn.Module.__init__(self)\n",
    "        self.device = device\n",
    "        self.l1 = nn.Linear(num_input, num_hidden)\n",
    "        self.l2 = nn.Linear(num_hidden, num_output)\n",
    "        self.input_dim = num_input  #2 times the state size\n",
    "        self.hidden_dim = num_hidden\n",
    "        self.output_dim = num_output\n",
    "        \n",
    "    def forward(self,model,state,epsilon,goal):\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            if np.random.rand() < epsilon:\n",
    "                \n",
    "                combined = np.concatenate(state,goal)\n",
    "                if not torch.is_tensor(combined):\n",
    "                    combined_tensor = torch.Tensor(combined)\n",
    "\n",
    "                combined_tensor = combined_tensor.to(self.device)\n",
    "\n",
    "                forward_pass = nn.Sequential(\n",
    "                    self.l1,\n",
    "                    nn.ReLU(),\n",
    "                    self.l2\n",
    "                )\n",
    "                \n",
    "                output = forward_pass(combined_tensor)\n",
    "                a_probs = F.softmax(output)\n",
    "                \n",
    "                a = np.random.choice(len(a_probs), size=1,p=a_probs)\n",
    "            else:\n",
    "                Q_approx = model(state)\n",
    "                a = torch.argmax(Q_approx).item()\n",
    "        return a\n",
    "    \n",
    "class HindsightReplayMemory:\n",
    "    \n",
    "    def __init__(self, capacity, k,env_name):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.k = k\n",
    "        self.name = \"hindsight\"\n",
    "        self.goals = []\n",
    "        self.env_name = env_name\n",
    "        self.current_episode = []\n",
    "            \n",
    "        if env_name == \"Acrobot-v1\":\n",
    "            self.true_goal_func = lambda s: bool(-np.cos(s[0]) - np.cos(s[1] + s[0]) > 1.)\n",
    "            self.goal_func = lambda s1,s2: (s1 == s2).all()\n",
    "        elif env_name == \"MountainCar-v0\":\n",
    "            self.true_goal_func = lambda s: s[0] >= 0.5 \n",
    "            self.goal_func = lambda s1,s2: s1[0] == s2[0]\n",
    "        \n",
    "    def compute_reward(self,observed_state,goal):\n",
    "        \n",
    "        if self.goal_func(observed_state,goal):\n",
    "            return 0\n",
    "        \n",
    "        return -1\n",
    "\n",
    "    def push(self, transition):\n",
    "                \n",
    "        if len(self.memory) == self.capacity:\n",
    "            self.memory = self.memory[1:]   \n",
    "        \n",
    "        self.memory.append(transition)\n",
    "        self.current_episode.append(transition)\n",
    "        #goals = \n",
    "            \n",
    "    def add_future_goals(self):\n",
    "        #reward = compute_reward(transition[0],goal)\n",
    "\n",
    "        episode_len = len(self.current_episode)\n",
    "\n",
    "        for i in range(episode_len):\n",
    "            current_experience = self.current_episode[i]\n",
    "            observed_state = current_experience[3]\n",
    "            \n",
    "            amount_future = (episode_len - (i+1))\n",
    "            sample_size = self.k if amount_future > self.k else amount_future\n",
    "            sampled_trans = random.sample(self.current_episode[i+1:],sample_size)\n",
    "            #new_rewards = [self.compute_reward(observed_state,trans[3]) for trans in sampled_trans]\n",
    "            new_rewards = [self.compute_reward(observed_state,trans[0]) for trans in sampled_trans]\n",
    "            #if 0 in new_rewards:\n",
    "            #    print(new_rewards)\n",
    "            #local = []\n",
    "            \n",
    "            for new_r in new_rewards:\n",
    "                tmp_exp = list(current_experience)\n",
    "                tmp_exp[2] = new_r\n",
    "                tmp_exp = tuple(tmp_exp)\n",
    "                self.memory.append(tmp_exp)\n",
    "                #local.append(tmp_exp)\n",
    "            #if 0 in new_rewards:\n",
    "            #    print(local)\n",
    "            \n",
    "        self.current_episode = []\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        samples = random.sample(self.memory,batch_size)\n",
    "        \n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "def train_hindsight(model, memory, optimizer, batch_size, discount_factor):\n",
    "    # DO NOT MODIFY THIS FUNCTION\n",
    "    \n",
    "    # don't learn without some decent experience\n",
    "    if len(memory) < batch_size:\n",
    "        return None\n",
    "\n",
    "    # random transition batch is taken from experience replay memory\n",
    "    transitions = memory.sample(batch_size)\n",
    "    \n",
    "    # transition is a list of 4-tuples, instead we want 4 vectors (as torch.Tensor's)\n",
    "    state, action, reward, next_state, done = zip(*transitions)\n",
    "    \n",
    "    # convert to PyTorch and define types\n",
    "    state = torch.tensor(state, dtype=torch.float, device = model.device)\n",
    "    action = torch.tensor(action, dtype=torch.int64, device = model.device)  # Need 64 bit to use them as index\n",
    "    next_state = torch.tensor(next_state, dtype=torch.float, device = model.device)\n",
    "    reward = torch.tensor(reward, dtype=torch.float, device = model.device)\n",
    "    done = torch.tensor(done, dtype=torch.uint8)  # Boolean\n",
    "    \n",
    "    # compute the q value\n",
    "    q_val = compute_q_val(model, state, action)\n",
    "    \n",
    "    with torch.no_grad():  # Don't compute gradient info for the target (semi-gradient)\n",
    "        target = compute_target(model, reward, next_state, done, discount_factor)\n",
    "    \n",
    "    # loss is measured from error between current and newly expected Q values\n",
    "    loss = F.smooth_l1_loss(q_val, target)\n",
    "\n",
    "    # backpropagation of loss to Neural Network (PyTorch magic)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()  # Returns a Python scalar, and releases history (similar to .detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_q_val(model, state, action):\n",
    "    # YOUR CODE HERE\n",
    "    Q_approx = model(state)\n",
    "    action_values = torch.gather(Q_approx, dim=1, index=action.reshape(-1,1))\n",
    "    \n",
    "    return action_values\n",
    "    \n",
    "def compute_target(model, reward, next_state, done, discount_factor):\n",
    "    # done is a boolean (vector) that indicates if next_state is terminal (episode is done)\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    Q_approx = model(next_state)\n",
    "    max_Q = torch.max(Q_approx,dim=1)[0]\n",
    "    target = reward + discount_factor * max_Q\n",
    "\n",
    "    indices = torch.tensor(np.where(done),dtype=torch.long, device = model.device)\n",
    "    target = target.scatter(0, indices.reshape(-1), 0)\n",
    "    target = target.reshape(-1,1)\n",
    "        \n",
    "    return target\n",
    "\n",
    "def train(model, memory, optimizer, batch_size, discount_factor):\n",
    "    # DO NOT MODIFY THIS FUNCTION\n",
    "    \n",
    "    # don't learn without some decent experience\n",
    "    if len(memory) < batch_size:\n",
    "        return None\n",
    "\n",
    "    # random transition batch is taken from experience replay memory\n",
    "    transitions = memory.sample(batch_size)\n",
    "    \n",
    "    # transition is a list of 4-tuples, instead we want 4 vectors (as torch.Tensor's)\n",
    "    state, action, reward, next_state, done = zip(*transitions)\n",
    "    \n",
    "    # convert to PyTorch and define types\n",
    "    state = torch.tensor(state, dtype=torch.float, device = model.device)\n",
    "    action = torch.tensor(action, dtype=torch.int64, device = model.device)  # Need 64 bit to use them as index\n",
    "    next_state = torch.tensor(next_state, dtype=torch.float, device = model.device)\n",
    "    reward = torch.tensor(reward, dtype=torch.float, device = model.device)\n",
    "    done = torch.tensor(done, dtype=torch.uint8)  # Boolean\n",
    "    \n",
    "    # compute the q value\n",
    "    q_val = compute_q_val(model, state, action)\n",
    "    \n",
    "    with torch.no_grad():  # Don't compute gradient info for the target (semi-gradient)\n",
    "        target = compute_target(model, reward, next_state, done, discount_factor)\n",
    "    \n",
    "    # loss is measured from error between current and newly expected Q values\n",
    "    loss = F.smooth_l1_loss(q_val, target)\n",
    "\n",
    "    # backpropagation of loss to Neural Network (PyTorch magic)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()  # Returns a Python scalar, and releases history (similar to .detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episodes(train,select_action_func, model, memory, env, num_episodes, batch_size, discount_factor, learn_rate, \n",
    "                 beta_max_iter = 1000,beta_start = 0.4,beta_end = 1.0):\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), learn_rate)\n",
    "    \n",
    "    global_steps = 0  # Count the steps (do not reset at episode start, to compute epsilon)\n",
    "    episode_durations = []  #\n",
    "    \n",
    "    for i in tqdm(range(num_episodes)):\n",
    "        # YOUR CODE HERE\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        local_steps = 0\n",
    "        \n",
    "        while not done:\n",
    "            epsilon = get_epsilon(global_steps)\n",
    "            #if memory.name == \" hindsight\":\n",
    "            #    goal = ..\n",
    "            #    a = select_action_func(model, s, epsilon,goal)\n",
    "            #else:\n",
    "            a = select_action_func(model, s, epsilon)\n",
    "            observation,reward,done,info = env.step(a)\n",
    "            \n",
    "            global_steps += 1\n",
    "            local_steps += 1\n",
    "            \n",
    "            if memory.name == \"prioritized\":\n",
    "                memory.add(s, a, reward, observation, float(done))\n",
    "                beta = parameter_schedule(global_steps,beta_max_iter,beta_start,beta_end)\n",
    "                loss = train(model, memory, optimizer, batch_size, discount_factor,beta)\n",
    "            #elif memory.name == \"hindsight\":\n",
    "            #    memory.push((s, a, reward, observation, done),goal) \n",
    "            #    loss = train(model, memory, optimizer, batch_size, discount_factor)\n",
    "            else: #memory.name == \"uniform\" or memory.name == \"selective\" or memory.name == \"hindsight\":\n",
    "                memory.push((s, a, reward, observation, done))\n",
    "                loss = train(model, memory, optimizer, batch_size, discount_factor)\n",
    "\n",
    "            s = observation\n",
    "        \n",
    "        episode_durations.append(local_steps)\n",
    "        \n",
    "        if memory.name == \"hindsight\":\n",
    "            memory.add_future_goals()\n",
    "        \n",
    "        #Check for convergance to terminate perhaps?\n",
    "\n",
    "    return episode_durations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set multiple seeds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will seed the algorithm (before initializing QNetwork!) for reproducability\n",
    "\n",
    "if \"cuda\" in device:\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed = 42 \n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "env.seed(seed)\n",
    "np.random.seed(seed) #Added this seed for numpy, as used in selection action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = env_cartpole\n",
    "env = env_car\n",
    "#env = env_pen\n",
    "#env = env_acrobot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                          | 0/600 [00:00<?, ?it/s]\n",
      "  0%|▎                                                                                 | 2/600 [00:01<06:21,  1.57it/s]\n",
      "  1%|▌                                                                                 | 4/600 [00:02<06:51,  1.45it/s]\n",
      "  1%|▊                                                                                 | 6/600 [00:04<07:02,  1.40it/s]\n",
      "  1%|█                                                                                 | 8/600 [00:05<07:08,  1.38it/s]\n",
      "  2%|█▎                                                                               | 10/600 [00:07<07:16,  1.35it/s]\n",
      "  2%|█▌                                                                               | 12/600 [00:09<07:21,  1.33it/s]\n",
      "  2%|█▉                                                                               | 14/600 [00:10<07:36,  1.28it/s]\n",
      "  3%|██▏                                                                              | 16/600 [00:12<07:34,  1.29it/s]\n",
      "  3%|██▍                                                                              | 18/600 [00:13<07:32,  1.29it/s]\n",
      "  3%|██▋                                                                              | 20/600 [00:15<07:30,  1.29it/s]\n",
      "  4%|██▉                                                                              | 22/600 [00:16<07:30,  1.28it/s]\n",
      "  4%|███▏                                                                             | 24/600 [00:18<07:26,  1.29it/s]\n",
      "  4%|███▌                                                                             | 26/600 [00:20<07:26,  1.28it/s]\n",
      "  5%|███▊                                                                             | 28/600 [00:21<07:28,  1.28it/s]\n",
      "  5%|████                                                                             | 30/600 [00:23<07:24,  1.28it/s]\n",
      "  5%|████▎                                                                            | 32/600 [00:24<07:16,  1.30it/s]\n",
      "  6%|████▌                                                                            | 34/600 [00:26<07:12,  1.31it/s]\n",
      "  6%|████▊                                                                            | 36/600 [00:27<07:14,  1.30it/s]\n",
      "  6%|█████▏                                                                           | 38/600 [00:29<07:11,  1.30it/s]\n",
      "  7%|█████▍                                                                           | 40/600 [00:30<07:12,  1.30it/s]\n",
      "  7%|█████▋                                                                           | 42/600 [00:32<07:05,  1.31it/s]\n",
      "  7%|█████▉                                                                           | 44/600 [00:33<07:05,  1.31it/s]\n",
      "  8%|██████▏                                                                          | 46/600 [00:35<07:04,  1.31it/s]\n",
      "  8%|██████▍                                                                          | 48/600 [00:36<07:01,  1.31it/s]\n",
      "  8%|██████▊                                                                          | 50/600 [00:38<06:55,  1.32it/s]\n",
      "  9%|███████                                                                          | 52/600 [00:39<06:55,  1.32it/s]\n",
      "  9%|███████▎                                                                         | 54/600 [00:41<07:02,  1.29it/s]\n",
      "  9%|███████▌                                                                         | 56/600 [00:43<07:01,  1.29it/s]\n",
      " 10%|███████▊                                                                         | 58/600 [00:44<06:59,  1.29it/s]\n",
      " 10%|████████                                                                         | 60/600 [00:46<06:58,  1.29it/s]\n",
      " 10%|████████▎                                                                        | 62/600 [00:47<06:56,  1.29it/s]\n",
      " 11%|████████▋                                                                        | 64/600 [00:49<07:00,  1.28it/s]\n",
      " 11%|████████▉                                                                        | 66/600 [00:50<06:56,  1.28it/s]\n",
      " 11%|█████████▏                                                                       | 68/600 [00:52<06:55,  1.28it/s]\n",
      " 12%|█████████▍                                                                       | 70/600 [00:53<06:49,  1.29it/s]\n",
      " 12%|█████████▋                                                                       | 72/600 [00:55<06:46,  1.30it/s]\n",
      " 12%|█████████▉                                                                       | 74/600 [00:56<06:41,  1.31it/s]\n",
      " 13%|██████████▎                                                                      | 76/600 [00:58<06:36,  1.32it/s]\n",
      " 13%|██████████▌                                                                      | 78/600 [00:59<06:34,  1.32it/s]\n",
      " 13%|██████████▊                                                                      | 80/600 [01:01<06:37,  1.31it/s]\n",
      " 14%|███████████                                                                      | 82/600 [01:03<06:33,  1.32it/s]\n",
      " 14%|███████████▎                                                                     | 84/600 [01:04<06:30,  1.32it/s]\n",
      " 14%|███████████▌                                                                     | 86/600 [01:06<06:31,  1.31it/s]\n",
      " 15%|███████████▉                                                                     | 88/600 [01:07<06:31,  1.31it/s]\n",
      " 15%|████████████▏                                                                    | 90/600 [01:09<06:28,  1.31it/s]\n",
      " 15%|████████████▍                                                                    | 92/600 [01:10<06:27,  1.31it/s]\n",
      " 16%|████████████▋                                                                    | 94/600 [01:12<06:21,  1.33it/s]\n",
      " 16%|████████████▉                                                                    | 96/600 [01:13<06:18,  1.33it/s]\n",
      " 16%|█████████████▏                                                                   | 98/600 [01:15<06:20,  1.32it/s]\n",
      " 17%|█████████████▎                                                                  | 100/600 [01:16<06:16,  1.33it/s]\n",
      " 17%|█████████████▌                                                                  | 102/600 [01:18<06:16,  1.32it/s]\n",
      " 17%|█████████████▊                                                                  | 104/600 [01:19<06:18,  1.31it/s]\n",
      " 18%|██████████████▏                                                                 | 106/600 [01:21<06:14,  1.32it/s]\n",
      " 18%|██████████████▍                                                                 | 108/600 [01:22<06:10,  1.33it/s]\n",
      " 18%|██████████████▋                                                                 | 110/600 [01:24<06:06,  1.34it/s]\n",
      " 19%|██████████████▉                                                                 | 112/600 [01:25<06:07,  1.33it/s]\n",
      " 19%|███████████████▏                                                                | 114/600 [01:27<06:05,  1.33it/s]\n",
      " 19%|███████████████▍                                                                | 116/600 [01:28<06:11,  1.30it/s]\n",
      " 20%|███████████████▋                                                                | 118/600 [01:30<06:08,  1.31it/s]\n",
      " 20%|████████████████                                                                | 120/600 [01:31<06:06,  1.31it/s]\n",
      " 20%|████████████████▎                                                               | 122/600 [01:33<06:04,  1.31it/s]\n",
      " 21%|████████████████▌                                                               | 124/600 [01:34<06:00,  1.32it/s]\n",
      " 21%|████████████████▊                                                               | 126/600 [01:36<05:59,  1.32it/s]\n",
      " 21%|█████████████████                                                               | 128/600 [01:37<06:02,  1.30it/s]\n",
      " 22%|█████████████████▎                                                              | 130/600 [01:39<06:02,  1.30it/s]\n",
      " 22%|█████████████████▌                                                              | 132/600 [01:41<05:56,  1.31it/s]\n",
      " 22%|█████████████████▊                                                              | 134/600 [01:42<05:57,  1.30it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████▏                                                             | 136/600 [01:44<05:52,  1.32it/s]\n",
      " 23%|██████████████████▍                                                             | 138/600 [01:45<05:53,  1.31it/s]\n",
      " 23%|██████████████████▋                                                             | 140/600 [01:47<05:52,  1.31it/s]\n",
      " 24%|██████████████████▉                                                             | 142/600 [01:48<05:53,  1.30it/s]\n",
      " 24%|███████████████████▏                                                            | 144/600 [01:50<05:55,  1.28it/s]\n",
      " 24%|███████████████████▍                                                            | 146/600 [01:51<05:51,  1.29it/s]\n",
      " 25%|███████████████████▋                                                            | 148/600 [01:53<05:43,  1.32it/s]\n",
      " 25%|████████████████████                                                            | 150/600 [01:54<05:47,  1.29it/s]\n",
      " 25%|████████████████████▎                                                           | 152/600 [01:56<05:43,  1.30it/s]\n",
      " 26%|████████████████████▌                                                           | 154/600 [01:57<05:39,  1.31it/s]\n",
      " 26%|████████████████████▊                                                           | 156/600 [01:59<05:35,  1.32it/s]\n",
      " 26%|█████████████████████                                                           | 158/600 [02:00<05:30,  1.34it/s]\n",
      " 27%|█████████████████████▎                                                          | 160/600 [02:02<05:29,  1.34it/s]\n",
      " 27%|█████████████████████▌                                                          | 162/600 [02:03<05:33,  1.31it/s]\n",
      " 27%|█████████████████████▊                                                          | 164/600 [02:05<05:34,  1.30it/s]\n",
      " 28%|██████████████████████▏                                                         | 166/600 [02:07<05:35,  1.29it/s]\n",
      " 28%|██████████████████████▍                                                         | 168/600 [02:08<05:33,  1.30it/s]\n",
      " 28%|██████████████████████▋                                                         | 170/600 [02:10<05:29,  1.30it/s]\n",
      " 29%|██████████████████████▉                                                         | 172/600 [02:11<05:27,  1.31it/s]\n",
      " 29%|███████████████████████▏                                                        | 174/600 [02:13<05:28,  1.30it/s]\n",
      " 29%|███████████████████████▍                                                        | 176/600 [02:14<05:26,  1.30it/s]\n",
      " 30%|███████████████████████▋                                                        | 178/600 [02:16<05:22,  1.31it/s]\n",
      " 30%|████████████████████████                                                        | 180/600 [02:17<05:20,  1.31it/s]\n",
      " 30%|████████████████████████▎                                                       | 182/600 [02:19<05:22,  1.30it/s]\n",
      " 31%|████████████████████████▌                                                       | 184/600 [02:20<05:22,  1.29it/s]\n",
      " 31%|████████████████████████▊                                                       | 186/600 [02:22<05:21,  1.29it/s]\n",
      " 31%|█████████████████████████                                                       | 188/600 [02:23<05:18,  1.29it/s]\n",
      " 32%|█████████████████████████▎                                                      | 190/600 [02:25<05:15,  1.30it/s]\n",
      " 32%|█████████████████████████▌                                                      | 192/600 [02:27<05:15,  1.29it/s]\n",
      " 32%|█████████████████████████▊                                                      | 194/600 [02:28<05:15,  1.29it/s]\n",
      " 33%|██████████████████████████▏                                                     | 196/600 [02:30<05:15,  1.28it/s]\n",
      " 33%|██████████████████████████▍                                                     | 198/600 [02:31<05:14,  1.28it/s]\n",
      " 33%|██████████████████████████▋                                                     | 200/600 [02:33<05:11,  1.28it/s]\n",
      " 34%|██████████████████████████▉                                                     | 202/600 [02:34<05:04,  1.31it/s]\n",
      " 34%|███████████████████████████▏                                                    | 204/600 [02:36<05:01,  1.31it/s]\n",
      " 34%|███████████████████████████▍                                                    | 206/600 [02:37<04:58,  1.32it/s]\n",
      " 35%|███████████████████████████▋                                                    | 208/600 [02:39<04:56,  1.32it/s]\n",
      " 35%|████████████████████████████                                                    | 210/600 [02:40<04:56,  1.32it/s]\n",
      " 35%|████████████████████████████▎                                                   | 212/600 [02:42<04:51,  1.33it/s]\n",
      " 36%|████████████████████████████▌                                                   | 214/600 [02:43<04:50,  1.33it/s]\n",
      " 36%|████████████████████████████▊                                                   | 216/600 [02:45<04:50,  1.32it/s]\n",
      " 36%|█████████████████████████████                                                   | 218/600 [02:46<04:44,  1.34it/s]\n",
      " 37%|█████████████████████████████▎                                                  | 220/600 [02:48<04:44,  1.33it/s]\n",
      " 37%|█████████████████████████████▌                                                  | 222/600 [02:49<04:43,  1.33it/s]\n",
      " 37%|█████████████████████████████▊                                                  | 224/600 [02:51<04:42,  1.33it/s]\n",
      " 38%|██████████████████████████████▏                                                 | 226/600 [02:52<04:42,  1.32it/s]\n",
      " 38%|██████████████████████████████▍                                                 | 228/600 [02:54<04:41,  1.32it/s]\n",
      " 38%|██████████████████████████████▋                                                 | 230/600 [02:55<04:38,  1.33it/s]\n",
      " 39%|██████████████████████████████▉                                                 | 232/600 [02:57<04:34,  1.34it/s]\n",
      " 39%|███████████████████████████████▏                                                | 234/600 [02:58<04:33,  1.34it/s]\n",
      " 39%|███████████████████████████████▍                                                | 236/600 [03:00<04:29,  1.35it/s]\n",
      " 40%|███████████████████████████████▋                                                | 238/600 [03:01<04:27,  1.35it/s]\n",
      " 40%|████████████████████████████████                                                | 240/600 [03:03<04:25,  1.36it/s]\n",
      " 40%|████████████████████████████████▎                                               | 242/600 [03:04<04:28,  1.33it/s]\n",
      " 41%|████████████████████████████████▌                                               | 244/600 [03:06<04:27,  1.33it/s]\n",
      " 41%|████████████████████████████████▊                                               | 246/600 [03:07<04:25,  1.34it/s]\n",
      " 41%|█████████████████████████████████                                               | 248/600 [03:09<04:22,  1.34it/s]\n",
      " 42%|█████████████████████████████████▎                                              | 250/600 [03:10<04:19,  1.35it/s]\n",
      " 42%|█████████████████████████████████▌                                              | 252/600 [03:12<04:16,  1.36it/s]\n",
      " 42%|█████████████████████████████████▊                                              | 254/600 [03:13<04:17,  1.34it/s]\n",
      " 43%|██████████████████████████████████▏                                             | 256/600 [03:15<04:14,  1.35it/s]\n",
      " 43%|██████████████████████████████████▍                                             | 258/600 [03:16<04:18,  1.32it/s]\n",
      " 43%|██████████████████████████████████▋                                             | 260/600 [03:18<04:19,  1.31it/s]\n",
      " 44%|██████████████████████████████████▉                                             | 262/600 [03:19<04:15,  1.32it/s]\n",
      " 44%|███████████████████████████████████▏                                            | 264/600 [03:21<04:16,  1.31it/s]\n",
      " 44%|███████████████████████████████████▍                                            | 266/600 [03:22<04:19,  1.29it/s]\n",
      " 45%|███████████████████████████████████▋                                            | 268/600 [03:24<04:21,  1.27it/s]\n",
      " 45%|████████████████████████████████████                                            | 270/600 [03:26<04:21,  1.26it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████████████████████████████▎                                           | 272/600 [03:27<04:16,  1.28it/s]\n",
      " 46%|████████████████████████████████████▌                                           | 274/600 [03:29<04:13,  1.29it/s]\n",
      " 46%|████████████████████████████████████▊                                           | 276/600 [03:30<04:10,  1.29it/s]\n",
      " 46%|█████████████████████████████████████                                           | 278/600 [03:32<04:06,  1.31it/s]\n",
      " 47%|█████████████████████████████████████▎                                          | 280/600 [03:33<04:04,  1.31it/s]\n",
      " 47%|█████████████████████████████████████▌                                          | 282/600 [03:35<04:02,  1.31it/s]\n",
      " 47%|█████████████████████████████████████▊                                          | 284/600 [03:36<04:03,  1.30it/s]\n",
      " 48%|██████████████████████████████████████▏                                         | 286/600 [03:38<04:00,  1.30it/s]\n",
      " 48%|██████████████████████████████████████▍                                         | 288/600 [03:39<04:01,  1.29it/s]\n",
      " 48%|██████████████████████████████████████▋                                         | 290/600 [03:41<03:57,  1.30it/s]\n",
      " 49%|██████████████████████████████████████▉                                         | 292/600 [03:42<03:55,  1.31it/s]\n",
      " 49%|███████████████████████████████████████▏                                        | 294/600 [03:44<03:55,  1.30it/s]\n",
      " 49%|███████████████████████████████████████▍                                        | 296/600 [03:46<03:54,  1.30it/s]\n",
      " 50%|███████████████████████████████████████▋                                        | 298/600 [03:47<03:50,  1.31it/s]\n",
      " 50%|████████████████████████████████████████                                        | 300/600 [03:49<03:53,  1.29it/s]\n",
      " 50%|████████████████████████████████████████▎                                       | 302/600 [03:50<03:52,  1.28it/s]\n",
      " 51%|████████████████████████████████████████▌                                       | 304/600 [03:52<03:51,  1.28it/s]\n",
      " 51%|████████████████████████████████████████▊                                       | 306/600 [03:53<03:51,  1.27it/s]\n",
      " 51%|█████████████████████████████████████████                                       | 308/600 [03:55<03:46,  1.29it/s]\n",
      " 52%|█████████████████████████████████████████▎                                      | 310/600 [03:56<03:42,  1.30it/s]\n",
      " 52%|█████████████████████████████████████████▌                                      | 312/600 [03:58<03:37,  1.33it/s]\n",
      " 52%|█████████████████████████████████████████▊                                      | 314/600 [03:59<03:35,  1.33it/s]\n",
      " 53%|██████████████████████████████████████████▏                                     | 316/600 [04:01<03:23,  1.40it/s]\n",
      " 53%|██████████████████████████████████████████▍                                     | 318/600 [04:02<03:22,  1.40it/s]\n",
      " 53%|██████████████████████████████████████████▋                                     | 320/600 [04:04<03:22,  1.38it/s]\n",
      " 54%|██████████████████████████████████████████▉                                     | 322/600 [04:05<03:24,  1.36it/s]\n",
      " 54%|███████████████████████████████████████████▏                                    | 324/600 [04:07<03:22,  1.36it/s]\n",
      " 54%|███████████████████████████████████████████▍                                    | 326/600 [04:08<03:21,  1.36it/s]\n",
      " 55%|███████████████████████████████████████████▋                                    | 328/600 [04:09<03:19,  1.36it/s]\n",
      " 55%|████████████████████████████████████████████                                    | 330/600 [04:11<03:17,  1.36it/s]\n",
      " 55%|████████████████████████████████████████████▎                                   | 332/600 [04:12<03:18,  1.35it/s]\n",
      " 56%|████████████████████████████████████████████▌                                   | 334/600 [04:14<03:18,  1.34it/s]\n",
      " 56%|████████████████████████████████████████████▊                                   | 336/600 [04:16<03:19,  1.32it/s]\n",
      " 56%|█████████████████████████████████████████████                                   | 338/600 [04:17<03:21,  1.30it/s]\n",
      " 57%|█████████████████████████████████████████████▎                                  | 340/600 [04:19<03:17,  1.32it/s]\n",
      " 57%|█████████████████████████████████████████████▌                                  | 342/600 [04:20<03:13,  1.33it/s]\n",
      " 57%|█████████████████████████████████████████████▊                                  | 344/600 [04:22<03:12,  1.33it/s]\n",
      " 58%|██████████████████████████████████████████████▏                                 | 346/600 [04:23<03:10,  1.34it/s]\n",
      " 58%|██████████████████████████████████████████████▍                                 | 348/600 [04:25<03:09,  1.33it/s]\n",
      " 58%|██████████████████████████████████████████████▋                                 | 350/600 [04:26<03:07,  1.33it/s]\n",
      " 59%|██████████████████████████████████████████████▉                                 | 352/600 [04:28<03:04,  1.34it/s]\n",
      " 59%|███████████████████████████████████████████████▏                                | 354/600 [04:29<03:03,  1.34it/s]\n",
      " 59%|███████████████████████████████████████████████▍                                | 356/600 [04:31<03:04,  1.32it/s]\n",
      " 60%|███████████████████████████████████████████████▋                                | 358/600 [04:32<03:02,  1.33it/s]\n",
      " 60%|████████████████████████████████████████████████                                | 360/600 [04:34<02:59,  1.34it/s]\n",
      " 60%|████████████████████████████████████████████████▎                               | 362/600 [04:35<02:59,  1.33it/s]\n",
      " 61%|████████████████████████████████████████████████▌                               | 364/600 [04:37<02:58,  1.32it/s]\n",
      " 61%|████████████████████████████████████████████████▊                               | 366/600 [04:38<02:54,  1.34it/s]\n",
      " 61%|█████████████████████████████████████████████████                               | 368/600 [04:40<02:53,  1.34it/s]\n",
      " 62%|█████████████████████████████████████████████████▎                              | 370/600 [04:41<02:50,  1.35it/s]\n",
      " 62%|█████████████████████████████████████████████████▌                              | 372/600 [04:43<02:49,  1.34it/s]\n",
      " 62%|█████████████████████████████████████████████████▊                              | 374/600 [04:44<02:49,  1.33it/s]\n",
      " 63%|██████████████████████████████████████████████████▏                             | 376/600 [04:46<02:47,  1.34it/s]\n",
      " 63%|██████████████████████████████████████████████████▍                             | 378/600 [04:47<02:46,  1.33it/s]\n",
      " 63%|██████████████████████████████████████████████████▋                             | 380/600 [04:49<02:48,  1.31it/s]\n",
      " 64%|██████████████████████████████████████████████████▉                             | 382/600 [04:50<02:44,  1.32it/s]\n",
      " 64%|███████████████████████████████████████████████████▏                            | 384/600 [04:52<02:44,  1.31it/s]\n",
      " 64%|███████████████████████████████████████████████████▍                            | 386/600 [04:53<02:43,  1.31it/s]\n",
      " 65%|███████████████████████████████████████████████████▋                            | 388/600 [04:55<02:39,  1.33it/s]\n",
      " 65%|████████████████████████████████████████████████████                            | 390/600 [04:56<02:37,  1.34it/s]\n",
      " 65%|████████████████████████████████████████████████████▎                           | 392/600 [04:58<02:37,  1.32it/s]\n",
      " 66%|████████████████████████████████████████████████████▌                           | 394/600 [04:59<02:35,  1.33it/s]\n",
      " 66%|████████████████████████████████████████████████████▊                           | 396/600 [05:01<02:33,  1.33it/s]\n",
      " 66%|█████████████████████████████████████████████████████                           | 398/600 [05:02<02:31,  1.34it/s]\n",
      " 67%|█████████████████████████████████████████████████████▎                          | 400/600 [05:04<02:29,  1.34it/s]\n",
      " 67%|█████████████████████████████████████████████████████▌                          | 402/600 [05:05<02:28,  1.34it/s]\n",
      " 67%|█████████████████████████████████████████████████████▊                          | 404/600 [05:07<02:29,  1.31it/s]\n",
      " 68%|██████████████████████████████████████████████████████▏                         | 406/600 [05:08<02:25,  1.33it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████████▍                         | 408/600 [05:10<02:23,  1.34it/s]\n",
      " 68%|██████████████████████████████████████████████████████▋                         | 410/600 [05:11<02:24,  1.32it/s]\n",
      " 69%|██████████████████████████████████████████████████████▉                         | 412/600 [05:13<02:20,  1.34it/s]\n",
      " 69%|███████████████████████████████████████████████████████▏                        | 414/600 [05:14<02:20,  1.32it/s]\n",
      " 69%|███████████████████████████████████████████████████████▍                        | 416/600 [05:16<02:19,  1.32it/s]\n",
      " 70%|███████████████████████████████████████████████████████▋                        | 418/600 [05:17<02:19,  1.30it/s]\n",
      " 70%|████████████████████████████████████████████████████████                        | 420/600 [05:19<02:14,  1.34it/s]\n",
      " 70%|████████████████████████████████████████████████████████▎                       | 422/600 [05:20<02:10,  1.36it/s]\n",
      " 71%|████████████████████████████████████████████████████████▌                       | 424/600 [05:22<02:10,  1.35it/s]\n",
      " 71%|████████████████████████████████████████████████████████▊                       | 426/600 [05:23<02:08,  1.35it/s]\n",
      " 71%|█████████████████████████████████████████████████████████                       | 428/600 [05:25<02:06,  1.36it/s]\n",
      " 72%|█████████████████████████████████████████████████████████▎                      | 430/600 [05:26<02:06,  1.34it/s]\n",
      " 72%|█████████████████████████████████████████████████████████▌                      | 432/600 [05:28<02:04,  1.35it/s]\n",
      " 72%|█████████████████████████████████████████████████████████▊                      | 434/600 [05:29<02:03,  1.34it/s]\n",
      " 73%|██████████████████████████████████████████████████████████▏                     | 436/600 [05:31<02:02,  1.34it/s]\n",
      " 73%|██████████████████████████████████████████████████████████▍                     | 438/600 [05:32<02:03,  1.31it/s]\n",
      " 73%|██████████████████████████████████████████████████████████▋                     | 440/600 [05:34<02:02,  1.30it/s]\n",
      " 74%|██████████████████████████████████████████████████████████▉                     | 442/600 [05:35<02:04,  1.27it/s]\n",
      " 74%|███████████████████████████████████████████████████████████▏                    | 444/600 [05:37<02:02,  1.28it/s]\n",
      " 74%|███████████████████████████████████████████████████████████▍                    | 446/600 [05:38<01:59,  1.29it/s]\n",
      " 75%|███████████████████████████████████████████████████████████▋                    | 448/600 [05:40<01:56,  1.30it/s]\n",
      " 75%|████████████████████████████████████████████████████████████                    | 450/600 [05:41<01:54,  1.32it/s]\n",
      " 75%|████████████████████████████████████████████████████████████▎                   | 452/600 [05:43<01:52,  1.32it/s]\n",
      " 76%|████████████████████████████████████████████████████████████▌                   | 454/600 [05:44<01:50,  1.33it/s]\n",
      " 76%|████████████████████████████████████████████████████████████▊                   | 456/600 [05:46<01:47,  1.34it/s]\n",
      " 76%|█████████████████████████████████████████████████████████████                   | 458/600 [05:47<01:47,  1.33it/s]\n",
      " 77%|█████████████████████████████████████████████████████████████▎                  | 460/600 [05:49<01:44,  1.34it/s]\n",
      " 77%|█████████████████████████████████████████████████████████████▌                  | 462/600 [05:50<01:43,  1.34it/s]\n",
      " 77%|█████████████████████████████████████████████████████████████▊                  | 464/600 [05:52<01:40,  1.35it/s]\n",
      " 78%|██████████████████████████████████████████████████████████████▏                 | 466/600 [05:53<01:38,  1.37it/s]\n",
      " 78%|██████████████████████████████████████████████████████████████▍                 | 468/600 [05:55<01:37,  1.35it/s]\n",
      " 78%|██████████████████████████████████████████████████████████████▋                 | 470/600 [05:56<01:36,  1.35it/s]\n",
      " 79%|██████████████████████████████████████████████████████████████▉                 | 472/600 [05:58<01:34,  1.35it/s]\n",
      " 79%|███████████████████████████████████████████████████████████████▏                | 474/600 [05:59<01:33,  1.35it/s]\n",
      " 79%|███████████████████████████████████████████████████████████████▍                | 476/600 [06:01<01:31,  1.35it/s]\n",
      " 80%|███████████████████████████████████████████████████████████████▋                | 478/600 [06:02<01:28,  1.37it/s]\n",
      " 80%|████████████████████████████████████████████████████████████████                | 480/600 [06:04<01:26,  1.38it/s]\n",
      " 80%|████████████████████████████████████████████████████████████████▎               | 482/600 [06:05<01:24,  1.39it/s]\n",
      " 81%|████████████████████████████████████████████████████████████████▌               | 484/600 [06:06<01:23,  1.38it/s]\n",
      " 81%|████████████████████████████████████████████████████████████████▊               | 486/600 [06:08<01:22,  1.38it/s]\n",
      " 81%|█████████████████████████████████████████████████████████████████               | 488/600 [06:09<01:20,  1.39it/s]\n",
      " 82%|█████████████████████████████████████████████████████████████████▎              | 490/600 [06:11<01:21,  1.36it/s]\n",
      " 82%|█████████████████████████████████████████████████████████████████▌              | 492/600 [06:12<01:20,  1.34it/s]\n",
      " 82%|█████████████████████████████████████████████████████████████████▊              | 494/600 [06:14<01:18,  1.34it/s]\n",
      " 83%|██████████████████████████████████████████████████████████████████▏             | 496/600 [06:15<01:18,  1.33it/s]\n",
      " 83%|██████████████████████████████████████████████████████████████████▍             | 498/600 [06:17<01:15,  1.35it/s]\n",
      " 83%|██████████████████████████████████████████████████████████████████▋             | 500/600 [06:18<01:15,  1.33it/s]\n",
      " 84%|██████████████████████████████████████████████████████████████████▉             | 502/600 [06:20<01:13,  1.33it/s]\n",
      " 84%|███████████████████████████████████████████████████████████████████▏            | 504/600 [06:21<01:11,  1.35it/s]\n",
      " 84%|███████████████████████████████████████████████████████████████████▍            | 506/600 [06:23<01:10,  1.34it/s]\n",
      " 85%|███████████████████████████████████████████████████████████████████▋            | 508/600 [06:24<01:07,  1.36it/s]\n",
      " 85%|████████████████████████████████████████████████████████████████████            | 510/600 [06:26<01:06,  1.36it/s]\n",
      " 85%|████████████████████████████████████████████████████████████████████▎           | 512/600 [06:27<01:04,  1.37it/s]\n",
      " 86%|████████████████████████████████████████████████████████████████████▌           | 514/600 [06:29<01:02,  1.37it/s]\n",
      " 86%|████████████████████████████████████████████████████████████████████▊           | 516/600 [06:30<01:01,  1.36it/s]\n",
      " 86%|█████████████████████████████████████████████████████████████████████           | 518/600 [06:32<01:00,  1.34it/s]\n",
      " 87%|█████████████████████████████████████████████████████████████████████▎          | 520/600 [06:33<00:59,  1.35it/s]\n",
      " 87%|█████████████████████████████████████████████████████████████████████▌          | 522/600 [06:35<00:56,  1.37it/s]\n",
      " 87%|█████████████████████████████████████████████████████████████████████▊          | 524/600 [06:36<00:55,  1.36it/s]\n",
      " 88%|██████████████████████████████████████████████████████████████████████▏         | 526/600 [06:37<00:53,  1.39it/s]\n",
      " 88%|██████████████████████████████████████████████████████████████████████▍         | 528/600 [06:39<00:52,  1.38it/s]\n",
      " 88%|██████████████████████████████████████████████████████████████████████▋         | 530/600 [06:40<00:51,  1.36it/s]\n",
      " 89%|██████████████████████████████████████████████████████████████████████▉         | 532/600 [06:42<00:50,  1.36it/s]\n",
      " 89%|███████████████████████████████████████████████████████████████████████▏        | 534/600 [06:43<00:49,  1.34it/s]\n",
      " 89%|███████████████████████████████████████████████████████████████████████▍        | 536/600 [06:45<00:48,  1.32it/s]\n",
      " 90%|███████████████████████████████████████████████████████████████████████▋        | 538/600 [06:46<00:45,  1.35it/s]\n",
      " 90%|████████████████████████████████████████████████████████████████████████        | 540/600 [06:48<00:44,  1.34it/s]\n",
      " 90%|████████████████████████████████████████████████████████████████████████▎       | 542/600 [06:49<00:43,  1.33it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|████████████████████████████████████████████████████████████████████████▌       | 544/600 [06:51<00:42,  1.32it/s]\n",
      " 91%|████████████████████████████████████████████████████████████████████████▊       | 546/600 [06:52<00:40,  1.34it/s]\n",
      " 91%|█████████████████████████████████████████████████████████████████████████       | 548/600 [06:54<00:39,  1.32it/s]\n",
      " 92%|█████████████████████████████████████████████████████████████████████████▎      | 550/600 [06:55<00:37,  1.33it/s]\n",
      " 92%|█████████████████████████████████████████████████████████████████████████▌      | 552/600 [06:57<00:36,  1.30it/s]\n",
      " 92%|█████████████████████████████████████████████████████████████████████████▊      | 554/600 [06:59<00:34,  1.32it/s]\n",
      " 93%|██████████████████████████████████████████████████████████████████████████▏     | 556/600 [07:00<00:33,  1.33it/s]\n",
      " 93%|██████████████████████████████████████████████████████████████████████████▍     | 558/600 [07:02<00:32,  1.31it/s]\n",
      " 93%|██████████████████████████████████████████████████████████████████████████▋     | 560/600 [07:03<00:30,  1.30it/s]\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▉     | 562/600 [07:05<00:28,  1.32it/s]\n",
      " 94%|███████████████████████████████████████████████████████████████████████████▏    | 564/600 [07:06<00:27,  1.31it/s]\n",
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 566/600 [07:08<00:26,  1.30it/s]\n",
      " 95%|███████████████████████████████████████████████████████████████████████████▋    | 568/600 [07:09<00:24,  1.29it/s]\n",
      " 95%|████████████████████████████████████████████████████████████████████████████    | 570/600 [07:10<00:20,  1.44it/s]\n",
      " 96%|████████████████████████████████████████████████████████████████████████████▍   | 573/600 [07:12<00:16,  1.60it/s]\n",
      " 96%|████████████████████████████████████████████████████████████████████████████▋   | 575/600 [07:13<00:14,  1.68it/s]\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████   | 578/600 [07:14<00:12,  1.77it/s]\n",
      " 97%|█████████████████████████████████████████████████████████████████████████████▍  | 581/600 [07:16<00:10,  1.87it/s]\n",
      " 97%|█████████████████████████████████████████████████████████████████████████████▊  | 584/600 [07:17<00:08,  1.90it/s]\n",
      " 98%|██████████████████████████████████████████████████████████████████████████████▏ | 586/600 [07:19<00:08,  1.63it/s]\n",
      " 98%|██████████████████████████████████████████████████████████████████████████████▍ | 588/600 [07:20<00:07,  1.50it/s]\n",
      " 98%|██████████████████████████████████████████████████████████████████████████████▋ | 590/600 [07:22<00:07,  1.43it/s]\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████▉ | 592/600 [07:23<00:05,  1.38it/s]\n",
      " 99%|███████████████████████████████████████████████████████████████████████████████▏| 594/600 [07:25<00:04,  1.37it/s]\n",
      " 99%|███████████████████████████████████████████████████████████████████████████████▍| 596/600 [07:27<00:02,  1.35it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████▋| 598/600 [07:28<00:01,  1.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [07:30<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration time:  450.0850245952606\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameters\n",
    "num_episodes = 100\n",
    "batch_size = 64\n",
    "discount_factor = 0.8\n",
    "learn_rate = 1e-3\n",
    "buffer_size = 10000\n",
    "\n",
    "#Parameters for network, e.g. hidden dim\n",
    "num_input = len(env.observation_space.sample())\n",
    "num_hidden = 128\n",
    "num_output = env.action_space.n\n",
    "\n",
    "#Parameters for schedule of beta and alpha for prioritized replay\n",
    "beta_max_iter = 1000\n",
    "beta_start = 0.4\n",
    "beta_end = 1.0\n",
    "prioritized_replay_alpha = 0.6\n",
    "#prioritized_replay_eps=1e-6 Set default in the training function\n",
    "\n",
    "#Parameters for selective\n",
    "episodic_buffer_size = 12000\n",
    "\n",
    "#Parameters for hindsight\n",
    "num_policy_hidden = 128\n",
    "k = 4\n",
    "env_name = env.unwrapped.spec.id\n",
    "bigger_buffer_size = 10000 * k\n",
    "\n",
    "#Picking the memory\n",
    "memory_method = 4\n",
    "if memory_method == 1:  #Uniform\n",
    "    memory = ReplayMemory(buffer_size)\n",
    "    train_func = train #Uniform\n",
    "    select_action_func = select_action #epsilon greedy\n",
    "    \n",
    "elif memory_method == 2:   #Prioritzed\n",
    "    memory = PrioritizedReplayBuffer(buffer_size, alpha=prioritized_replay_alpha)\n",
    "    train_func = train_prioritized #Prioritized Replay\n",
    "    select_action_func = select_action #epsilon greedy\n",
    "\n",
    "elif memory_method == 3:   #Selective\n",
    "    memory = SelectiveReplayMemory(buffer_size,episodic_buffer_size)\n",
    "    train_func = train #same way as uniform\n",
    "    select_action_func = select_action #epsilon greedy\n",
    "\n",
    "elif memory_method == 4: #Hindsight\n",
    "    memory = HindsightReplayMemory(bigger_buffer_size,k,env_name)\n",
    "    train_func = train #same way as uniform\n",
    "    #select_action_func = Epsilon_Greedy_Goal(device,2*num_input,num_policy_hidden,num_output)\n",
    "    select_action_func = select_action #epsilon greedy\n",
    "    \n",
    "\n",
    "#Initializing model\n",
    "model = QNetwork(device,num_input,num_hidden,num_output)\n",
    "model = model.to(device)\n",
    "\n",
    "#Running\n",
    "start_time = time.time()\n",
    "episode_durations = run_episodes(train_func,select_action_func, model, memory, env, num_episodes, batch_size, discount_factor, learn_rate,\n",
    "                                beta_max_iter,beta_start,beta_end)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Total duration time: \", str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Episode durations per episode')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de5hcVZnv8e+v0xAuCSAkIJdIZAgoPkDAqCiMg6gcBvAyYo6i4w0VPScenTkcFGaY8TI6o/PMUVHnyDBIoqKoA6KiHpFhxIzAQRINEG6CEkwETCDcVUjS7/ljr+raXb2ruuvSXbt2/z7P009VrV21a62q6rdWvXvttRQRmJlZtQz1uwJmZtZ7Du5mZhXk4G5mVkEO7mZmFeTgbmZWQQ7uZmYV5OA+A0n6v5Le0uN9fkjSRT3a1wpJH+3Fvib5fG+U9MPper6yk/S4pAN6vM+rJb2jl/u01ob7XQHrjKR1wF7Atlzxioh4z0SPjYg/nap6lZ2khcDdwHYRsRUgIr4CfKWP1SqViJjT7zpY9xzcB9srIuLf+12JMpE0KyK2TXzPapA0XPuSMstzWqaCJL1V0jWSPivpEUm3S3ppbvvoT2RJB0r6cbrfA5K+nrvfiyTdkLbdIOlFuW3PTI97TNKVwLyGOhwl6VpJD0u6UdKxLep7hKSfpX19HdihoS0/abh/SDowXV8h6fOSvi/pCeAlkk6S9HNJj0paL+lDuYevTJcPp/TDCxufY4J2Xy3p79Lr+5ikH0qal7btIOkiSQ+mdt8gaa8mbV4n6WxJt0p6SNJySfl2nyxpTdrPtZIOa3jsByTdBDwhaVwnTdKzJF0pabOkOyT919y2FZLOS9sfS+/j/k1e3xNTHR+T9BtJ/yt3v3dKuis9x3ck7ZPb9vL0uXtE0ucANdTvNEm3pbZfkX9+65GI8N8A/gHrgJc12fZWYCvwl8B2wOuAR4Dd0/argXek6xcDf032Rb8DcEwq3x14CHgT2S+8U9PtPdL264BPArOBFwOPARelbfsCDwInpv2+PN2eX1DX7YF7cnV9LbAF+GiuLT9peEwAB6brK1Lbjs614Vjg0HT7MOC3wKvT/Remxw83vF4/mWS7rwZ+CRwE7JhufzxtexdwObATMAt4LrBLi/dvLbAgPec1uTYfCWwEXpD285Z0/9m5x65Jj92xYN87A+uBt6U2HAk8ADwn95o9lt632cC5+de44fW9D/jjdP1pwJHp+nFpn0emfXwWWJm2zQMeTe/ldum93Ur9M/dq4C7g2al+5wDX9vt/qmp/7rkPtm+lnl3t7525bRuBT0fEloj4OnAHcFLBPrYA+wP7RMQfIqLWgz0JuDMivhwRWyPiYuB24BWSngE8D/ibiHgyIlaSBbWaPwe+HxHfj4iRiLgSWEUW7BsdRRYAanW9BLihzdfh2xFxTXquP0TE1RFxc7p9E9kX2J9Mcl9N2527z/KI+EVE/B74BrA4lW8B9iALjNsiYnVEPNriuT4XEesjYjPwMbIvEoB3Av8SEden/XwReJLstar5THrs7wv2ezKwLiKWpzb8DLiULNjWfC8iVkbEk2Rf7i+UtKBgX1uAQyTtEhEPpX0BvBG4MCJ+lvZxdtrHQrL3+daIuCQitgCfBu7P7fNdwD9ExG2RpZT+Hljs3ntvObgPtldHxG65v3/NbftNRORnhbsH2Ifx3k/2k/mnkm6RdFoq3yc9Ju8esl75PsBDEfFEw7aa/YGl+S8e4Bhg74Ln36dJXduxPn9D0gsk/UjSJkmPAO+mIW3UQqt21+QD1e+A2gHILwNXAF+TdK+kf5S03STrnX9/9gfOaHj9FjD2/RvT5gb7Ay9oePwbgacXPT4iHgc2U/z5OIUsWN+T0jcvTOVjXqe0jwepfz7y+4+G+u4PnJur22ayz2D+NbYuObhX176S8nnOZwD3Nt4pIu6PiHdGxD5kPar/k/Kt95L9E9Kwj9+Q/VR/mqSdG7bVrAe+3PDFs3NEfLygnvc1qWvNE2RpDgAk5QPUaDMabn8V+A6wICJ2Bc6jnvOdaBrUVu1uKf3y+HBEHAK8iKwH/eYWD8n3lPPvz3rgYw2v307pV8To07XY73rgxw2PnxMR/63ouSXNIUsNFX0+boiIVwF7At8i+6UCDa9T+izsQf3zkd+/Gtq6HnhXQ/12jIhrW7TJ2uTgXl17Au+VtJ2kpWT5ze833knSUkn7pZsPkQWNbem+B0l6g6RhSa8DDgG+GxH3kKVZPixpe0nHMDZtcRFZ+ua/SJqVDjQem3uevOvI8rHvTc/zGuD5ue03As+RtDgdcPzQJNo+F9gcEX+Q9HzgDbltm4ARoNk47qbtnuhJJb1E0qGSZpHlnLcwdqhqo2WS9pO0O/BXQO1g9r8C706/QCRpZ2UHiedOVIfku6kNb0rv/3aSnifp2bn7nCjpGEnbA38HXB8Rjb+Atld2DsCuKb3yaK49XwXelt6X2WSplesjYh3wPbL37DXKDva+l7G/Gs4Dzpb0nPQ8u6bPqPWQg/tgu1zZiI/a32W5bdcDi8gOen0MeG1EPFiwj+cB10t6nKy3+76IuDvd92TgDLKf2+8HTo6IB9Lj3kB2wG8z8EHgS7UdpiDxKrKAtYmsp3YmBZ+3iHgKeA3ZQc2HyA7+fjO3/RfAR4B/B+4EftK4jwL/HfiIpMeAv6Xe2yQifpdej2tSWiCfx2YS7W7l6cAlZEHwNuDHZF90zXwV+CHwq/T30VSHVWR598+RvSZ3kb0+kxIRjwHHA68n62HfD3yC7MBn/rk/SPb+PZcsbVPkTcA6SY+Spbf+PD3HVcDfkOXy7wP+KD0f6bVaCnyc7DVcRHbAuFa/y1J9vpb2uxaYsedeTBWNTXVaFUh6K9nIhGP6XRcrpuwktHdEH85TkLQC2BAR50z3c9v0cc/dzKyCHNzNzCrIaRkzswpyz93MrIJKMXHYvHnzYuHChf2uhpnZQFm9evUDETG/aFspgvvChQtZtWpVv6thZjZQJDU9m9tpGTOzCnJwNzOrIAd3M7MKcnA3M6sgB3czswqaMLhLWpDmxr4tzff9vlS+u7Jluu5Ml09L5ZL0GWXLb90k6cipboSZmY01mZ77VuCMiHg22UowyyQdApwFXBURi4Cr0m3IZndblP5OBz7f81qbmVlLE45zj4j7yKb0JCIek3Qb2YopryJbqxLgi2RrSX4glX8prb7y/yTtJmnvtJ+euv+RP/DV69tdtMdsrJ1mD/O2oxcye3jWaNmvNj3Ot9bcC02m5zjxsL151tN3Gb29bSRYfs3dPPr7LVNe35nguQt3508OGntuzrfX/IZfbny8o/0t2msurzh87EJTP7pjIz+/56GO69grBz19LicfVrQIVnfaOokprY94BNlc4XvVAnZE3Cdpz3S3fRm7pNaGVDYmuEs6naxnzzOekV94Z/J+++gf+OyP7urosWZQj92LF+zGUQfsMVr+pevuYcW16xizPlTuMfc+8gf+aenho2V33P8YH/3ebQCFj7HJi4A/mr8zV51x7JjyMy+5iae2jrT9+kbAjtvNGhfcP3L5rdz9wBN9f79OPmyf/gb3tBTXpcBfRMSjav6KFG0Y1/2JiPOB8wGWLFnS0exlhy/Yjbv/oWjNZ7PJuWHdZpaedx1bto2MKX9q2wjz5mzPqnNePu4xL/7HH7FtZOxHtnb7gjcv4WWH7DV1FZ4B3nvxz7lpw8PjyrduG+F/HHcgZxx/cFv7+8QPbucL/3n3uPIt20Z4zRH78snXLS541OCb1GiZtMjvpcBXIqK2Ss5vJe2dtu8NbEzlGxi7XuJ+FKzNaFYGQ6kr0hCriQhadGBsCg2peIHYgI7ekyHBSEF6LaKz/Q2KyYyWEfAF4LaI+GRu03eAt6TrbwG+nSt/cxo1cxTwyFTk2816YSj9c48U9MRnNfnHl7LgnxcpHFU4VkwbSeOCcURkwbiD/Q1JxV8WEaNf7lU0mbTM0WTrKN4saU0q+yuy9RG/IentwK/J1kyEbIHhE8nWffwd8Lae1tish2al/+7xaZb6tkZifM+yFosc3LsnwcjYLNno6zvUwQtc9GUB2a+1TvY3KCYzWuYnNP/CfGnB/QNY1mW9zKZF7Z97W8M//0gEQz7Fry+KAm6Mbmt/fyL7cmhMtY1EVPrL2B9fm9FqvfP20jIaN0KydlMdJQ4sT4zPkddudxKMa18Wje/ZyEzPuZtV2WhapuE/f1sEQy26iePTMl6usleGCtIo9eDe2QHV/D5qqp5zd3C3GW00LdPQcx9p1XNvtcMKB4vpMjQ0vpfdzTGN2pf0uC9kqp1zd3C3GW00LdPYcx+JpgdUKRwtM7rJuqaCoanZZTfBuOjXgHvuZhU1+pO9YXTGRPnYZqNlrHvZe1I81LSTYNw05z5S7XMZHNxtRms1WmZWk/+OVuGgysFiukjjTyqr3e7kgHXznHu1h646uNuM1ulomYIJNbJtva7gDNT6gGpn+4OCPD7OuZtVVrPRMiMTjpYZ3wu03hgqGmra1UlM2aVz7mYzSEfTD7TYX4U7gtOqaNgidPb61lJl41M94Z67WVU1n36gec89m1tmbJlPYuqdop77SBc999rb2DjCaSSodB7Nwd1mtFmjB1THlo9E8547NB+Hbd0bKhpq2oOce9HMn+65m1VUbf6YwrRM04nDmgeECseKadNytEwPe+4RnQ2tHBQO7jajNRsKua3FMLlssEyTnmXvqzjjZFP09m6cO865m808zc5QjWhxhirNc+7WAwU999HpB7oY516Uc69uaHdwtxmuk9EyLVU5WkyT7IBq8Tj3bs5Qzb/F9Rx+dd8wB3eb0eqjZcaWtx4tM35ln256ljbWUNFopG4mDisY597N6JtB4eBuM1rtH79w+oF2Rss4MdMzordT/ta+cPN7jC5+CQwKB3eb0SRlCyi3NVqm1f56WLkZaqhFzr2rM1RHCnruFY7uDu42480aUkHPvfk/vgpmLWQ0LWPdqvXO83n36OL1LZpbpmhN1apxcLcZb0hqckC1+WM8Wmbq1HraRcG4k3VtR89lKPiycM7drMJmDant6QeaqfLoi+ky2tPOlUXDtu7355y7WeVlU8yOLWt1arpoMVqmwsFiutRewrGjW7r/beTRMmYzTHYAb/wC2a1HyxSfQWndGyo4saw+uqWLnnvBl0WFY7uDu1lxWmaiA6rFKhwrpk1Rzr27ce4FJzGN1PZX3XfMwd1mvOLRMq2X2XNaZuqMjksfc0A1u+xmyt+iNI9z7mYV1ny0jOeW6YdeB+PCXwKjz1Xd6D5hcJd0oaSNktbmyg6XdJ2kmyVdLmmXVL69pOWp/EZJx05h3c16oigtM9JitEzr7nl1g8V0KRzdMnqjk5OYxufw3XPPrABOaCi7ADgrIg4FLgPOTOXvBEjlLwf+tyT/OrBSG9L4tEyrA6rFaZnqH6CbLkVrnvZi4rDCk5gq/IZNGHgjYiWwuaH4YGBlun4lcEq6fghwVXrcRuBhYElPamo2RWYNNUnLtJzyt3G0jPWKCoJx47Z2FKV56icxtb27gdFpr3ot8Mp0fSmwIF2/EXiVpGFJzwSem9tmVkrN5jJpFkg8WmZqFc2/3uspf0e6GFo5KDoN7qcByyStBuYCT6XyC4ENwCrg08C1wNaiHUg6XdIqSas2bdrUYTXMujdUMFpm2wSjZcbpYhk4G6t+ElO9rKuTjgq+LGZCz324kwdFxO3A8QCSDgJOSuVbgb+s3U/StcCdTfZxPnA+wJIlS/yr1vpmVk9Gy/gj3Cu1A9ljg3HnM4e16rlX+cu4o567pD3T5RBwDnBeur2TpJ3T9ZcDWyPi1h7V1WxKNI6WqQX6Vot1NFPdUDF9et1zL0rzdDPL5KCYsOcu6WLgWGCepA3AB4E5kpalu3wTWJ6u7wlcIWkE+A3wpp7X2KzHsrll6v/4tRRN69EyDQdUqz/4YtoUT/nrnHu7JgzuEXFqk03nFtx3HdlIGrOB0dhz3zZBzx2aLwNn3Ws1K2QnyxjWHlGYc6/wQO0KN81scrIDqvXbtV5d05WYWo6WqW5PcLoUjnMf6bznrhnac3dwtxlvVsMye7Wee/O0jJpOP1DhWDFt6uPS62Uj9a57x/sbO7Sys7oNEgd3m/GG1HhANbtsFajH59xnQLSYJoU5dzrvadenEK6XdTOF8KBwcLcZb2hIhae6Nz1DVZ44bCrVc+T1sq4WyE6XM22xjo7GuZtVySyJOzc+xpn/diMAT27Nuu5Nc+4t9lXhWDFtiuaC6WY0kgoP0FZ/4jAHd5vxjj5wD+558AmuueuB0bL999iJ5+yza9PHNJvP3brX+4nDCvY3AxbrcHC3Ge89xy3iPcctmvT9pfpKPnXpjEePlulafVz6+ODeyRFVL7NnZpPSKoBXOVhMl9HFNXJl9cU12t/f6JdF7gu5mxz+oHBwN+tAszNUrXutz1DtZLGO7NKLdZhZS2oxWqbCHcFpUzjOfRLDU5tp/Uugum+Yg7tZm3yG6tQqHC3TsK2z/TnnbmYT8GiZqVM8Lr3zYFw0cVh9WcTqRncHd7M2ZdMPNC6zV/2e4HQpWmavPkVvr3Lu2aVz7mY2ysvsTa2iYDx6QLWDiFWfW6Ze5tEyZlbIaZmpU5RzH+mq59583HyFY7uDu1knPFpm6oz2tHNfod1MF1D8ZVH9k84c3M3a1PogXHWDxXSpp2XqZaM99x5NHDYTFsh2cDfrwPi0jPMyvVKURokej5YZPYmpwtHdwd2sTYKmSXanZbrXalbIbs5QLVxmr8Lvl4O7WZs8WmZqFa15Ws+Rt6/WOy/MuVf429jB3awDHi0zdQoXyO6i51405W993Hx1ObibtUkUjZapfk9wuoweUB0p6Ll3MrcMXiDbzCahVQCvbqiYPkWjZbpZialwsQ6fxGRmRTzl79Spp2V6s0B24TJ7PonJzBoVpmW66FnaWEULZHfT0x4qGC3jnruZjeMpf6dWbXRLr6YLGB03P5I/oOqeu5kVaDb9gHWv1URf3eXc62XuuQOSLpS0UdLaXNnhkq6TdLOkyyXtksq3k/TFVH6bpLOnsvJm/aGmZ6hWOFZMoxZnqHYxcdjYlZi8zB7ACuCEhrILgLMi4lDgMuDMVL4UmJ3Knwu8S9LCntTUrCQcwKdWfeKwuu4WyE77KMi5V3no6oTBPSJWApsbig8GVqbrVwKn1O4O7CxpGNgReAp4tDdVNSuP8Yt1WK8ULos30vlomfrcMs65T8Za4JXp+lJgQbp+CfAEcB/wa+CfIqLxiwEASadLWiVp1aZNmzqshtn0K4wHHi3TM/WTmOplI128vsWzTPokpmZOA5ZJWg3MJeuhAzwf2AbsAzwTOEPSAUU7iIjzI2JJRCyZP39+h9Uwm34tR8tUOFhMl8LpB9JlJ69vUc+99sVR5Zz7cCcPiojbgeMBJB0EnJQ2vQH4QURsATZKugZYAvyqB3U1K41m0w9Y7/QqjVJ7zE3rH+Ebq9YDsHrdQ0C1e+4dBXdJe0bERklDwDnAeWnTr4HjJF0E7AQcBXy6JzU1KwmhpmeoVjdUTJ/CnHsXaZThoSGettN2/OCW+/nBLfePlm8/PMQuO2zXZW3La8LgLuli4FhgnqQNwAeBOZKWpbt8E1ierv9zur6W7HO+PCJu6nWlzfqpdVpm+upRVbVFsIvnc29/f7OGxH9+4Dge/t1TY8rnzt6OXXeawcE9Ik5tsuncgvs+TnaA1azSfBLT1CmexXHstnbNmT3MnNkdJSoGls9QNWuT1Hw+d08/0L3iWRyrP3Sx1xzczdrUKoA7+HSv6IzSmiofAO01B3ezDow/icmJmV4pWvO0dhKTY/vkzawklFkvtEzLWLdqvfM16x9m9nDW//zFxsfHbLOJObibtalleHHs6douOwwzJFh+zTqWX7NutHxuKrfJcXA364RHy0yZPebM5pqzjuPh320ZUz5/7myfAdwGB3ezNknjp/yliylpbby9d92RvXfdsd/VGGg+oGrWplbh2x1LKwsHd7MOeMpfKzsHd7M2tT6JyawcHNzN2tQ6LePwbuXg4G7WgXFzyzQWmPWZg7tZm7LRMsU5d/fbrSwc3M3a5NEyNggc3M06MD4t0596mDXj4G7WLjWfz90nMVlZOLibtallAHdst5JwcDfrAY+WsbJxcDdrk9Q8mPuAqpWFg7tZm1qOlpm2Wpi15uBu1oFm0w+YlYWDu1mbVDhaprYMnPvuVg4O7mZtarlA9jTWw6wVB3ezDoybfsBpGSsZB3ezNhWnZerbzMrAwd2sTa0CuM9QtbKYMLhLulDSRklrc2WHS7pO0s2SLpe0Syp/o6Q1ub8RSYunsgFm/eDRMlZ2k+m5rwBOaCi7ADgrIg4FLgPOBIiIr0TE4ohYDLwJWBcRa3pYX7MSUIvRMn2ojlmBCYN7RKwENjcUHwysTNevBE4peOipwMVd1c6shBzAbRB0mnNfC7wyXV8KLCi4z+toEdwlnS5plaRVmzZt6rAaZv3i0TJWbp0G99OAZZJWA3OBp/IbJb0A+F1ErC16MEBEnB8RSyJiyfz58zushtn0E82DuXv1VhbDnTwoIm4HjgeQdBBwUsNdXo9TMlZRHi1jg6Cj4C5pz4jYKGkIOAc4L7dtiCxV8+LeVNGsfMaPlnFexsplMkMhLwauAw6WtEHS24FTJf0CuB24F1iee8iLgQ0R8aupqLBZvwmNC+a1m07LWFlM2HOPiFObbDq3yf2vBo7qok5mpdY6LWNWDj5D1awD49IyfamFWXMO7mZtKhotU0/LuO9u5eDgbtamVgHcod3KwsHdrAPjDqg6MWMl4+Bu1oFmE4c5K2Nl4eBu1qaWo2Uc3a0kHNzNOtFksQ6zsnBwN2uT0Phg7jNUrWQc3M3a1Czz4oyMlYmDu1kHxo+WMSsXB3ezNoni0TLuuFuZOLibtal5Wsbh3crDwd2sA83WUDUrCwd3szZJGhfMnZaxsnFwN2tTsyDurIyViYO7WQfGp2XMysXB3axdajZaxl13Kw8Hd7M2NQ3iju1WIg7uZp3waBkrOQd3szZJBcHco2WsZBzczdrk0TI2CBzczTrg0TJWdg7uZm1S4WiZ8GgZKxUHd7M2NQviTstYmTi4m3Vg3JS/zstYyTi4m7WpMC2DR8tYuUwY3CVdKGmjpLW5ssMlXSfpZkmXS9olt+2wtO2WtH2Hqaq8WT+IggOq4Sl/rVwm03NfAZzQUHYBcFZEHApcBpwJIGkYuAh4d0Q8BzgW2NKrypqZ2eRMGNwjYiWwuaH4YGBlun4lcEq6fjxwU0TcmB77YERs61FdzcqhoIcehNMyViqd5tzXAq9M15cCC9L1g4CQdIWkn0l6f7MdSDpd0ipJqzZt2tRhNcymXy2I5w+qhpPuVjKdBvfTgGWSVgNzgadS+TBwDPDGdPlnkl5atIOIOD8ilkTEkvnz53dYDTMzKzLcyYMi4nayFAySDgJOSps2AD+OiAfStu8DRwJXdV9Vs3KoZWWyg6i58v5Ux6xQRz13SXumyyHgHOC8tOkK4DBJO6WDq38C3NqLipqVRe0kpvyAmYjwaBkrlckMhbwYuA44WNIGSW8HTpX0C+B24F5gOUBEPAR8ErgBWAP8LCK+N1WVNzOzYhOmZSLi1Cabzm1y/4vIhkOaVVI9LVM/ihp4+gErF5+hatam0dEyubLwfO5WMg7uZmYV5OBu1qb8aJmawAdUrVwc3M3aVAvi+aX2nJaxsnFwNzOrIAd3sw6NTct4tIyVi4O7WZuKgngW6B3drTwc3M3MKsjB3axNo9MPjFmwI5yWsVJxcDdr0+hQSI+WsRJzcDczqyAHd7M21RfrqJc1Tv9r1m8O7mZtqqdl6rJl9hzdrTwc3M3MKsjB3axN9dEyDQdU3XG3EnFwN2tTcVrGo2WsXBzczcwqyMHdrEPjR8u4727l4eBu1iYV5GViTJLGrP8c3M3MKsjB3axN9TVUx87566yMlYmDu1mbipfZc3C3cnFwNzOrIAd3szbV0zJ1EZ5+wMrFwd2sTaMLZOfPUMVpGSsXB3czswpycDdrU+H0A16sw0pmwuAu6UJJGyWtzZUdLuk6STdLulzSLql8oaTfS1qT/s6bysqb9UPhfO74DFUrl8n03FcAJzSUXQCcFRGHApcBZ+a2/TIiFqe/d/emmmZm1o4Jg3tErAQ2NxQfDKxM168ETulxvczKq3ZAdcwaquG0jJVKpzn3tcAr0/WlwILctmdK+rmkH0v642Y7kHS6pFWSVm3atKnDaphNv9Eg3pCWcXS3Muk0uJ8GLJO0GpgLPJXK7wOeERFHAP8T+GotH98oIs6PiCURsWT+/PkdVsPMzIoMd/KgiLgdOB5A0kHASan8SeDJdH21pF8CBwGrelJbsxIoGi2DR8tYyXTUc5e0Z7ocAs4Bzku350uala4fACwCftWbqpqVQ32ZvXpZEB4tY6UyYc9d0sXAscA8SRuADwJzJC1Ld/kmsDxdfzHwEUlbgW3AuyOi8WCsmZlNsQmDe0Sc2mTTuQX3vRS4tNtKmZVZPS3TsEB2n+pjVsRnqJq1qfAkJs/nbiXj4G5mVkEO7mZtKpxbBk/5a+Xi4G7WpvpomYacu2O7lYiDu5lZBTm4m7WryRqqZmXi4G7WpqLsS5aWcV7GysPB3cysghzczdpUX0M1X+opf61cHNzN2jR6ElPjGaqO7lYiDu5mZhXk4G7WJjUZLeOeu5WJg7tZmwrPUA2foWrl4uBuZlZBHa3EZDaT1Xrob13+U7aflfWPfvPw7zlwzzn9rJbZGA7uZm066oA9+LMj9uXJrdtGyxbtNYeXPmuvPtbKbCwHd7M2PX3XHfjU6xb3uxpmLTnnbmZWQQ7uZmYV5OBuZlZBDu5mZhXk4G5mVkEO7mZmFeTgbmZWQQ7uZmYVpIj+r/4oaRNwTxe7mAc80KPq9FuV2gLVak+V2gLVak+V2gKTb8/+ETG/aEMpgnu3JK2KiCX9rkcvVKktUK32VKktUK32VKkt0Jv2OC1jZlZBDu5mZhVUleB+fr8r0ENVagtUqz1VagtUqz1Vagv0oD2VyLmbmdlYVem5m5lZjoO7mVkFDXRwl3SCpDsk3SXprH7XZ2VMvJEAAAPfSURBVDIkXShpo6S1ubLdJV0p6c50+bRULkmfSe27SdKR/av5eJIWSPqRpNsk3SLpfal8UNuzg6SfSroxtefDqfyZkq5P7fm6pO1T+ex0+660fWE/619E0ixJP5f03XR7kNuyTtLNktZIWpXKBvWztpukSyTdnv5/XtjrtgxscJc0C/hn4E+BQ4BTJR3S31pNygrghIays4CrImIRcFW6DVnbFqW/04HPT1MdJ2srcEZEPBs4CliW3oNBbc+TwHERcTiwGDhB0lHAJ4BPpfY8BLw93f/twEMRcSDwqXS/snkfcFvu9iC3BeAlEbE4NwZ8UD9r5wI/iIhnAYeTvUe9bUtEDOQf8ELgitzts4Gz+12vSdZ9IbA2d/sOYO90fW/gjnT9X4BTi+5Xxj/g28DLq9AeYCfgZ8ALyM4UHE7lo5874Arghen6cLqf+l33XBv2S0HiOOC7gAa1Lale64B5DWUD91kDdgHubnx9e92Wge25A/sC63O3N6SyQbRXRNwHkC73TOUD08b0M/4I4HoGuD0pjbEG2AhcCfwSeDgitqa75Os82p60/RFgj+mtcUufBt4PjKTbezC4bQEI4IeSVks6PZUN4mftAGATsDylzC6QtDM9bssgB3cVlFVtXOdAtFHSHOBS4C8i4tFWdy0oK1V7ImJbRCwm6/U+H3h20d3SZWnbI+lkYGNErM4XF9y19G3JOToijiRLUyyT9OIW9y1ze4aBI4HPR8QRwBPUUzBFOmrLIAf3DcCC3O39gHv7VJdu/VbS3gDpcmMqL30bJW1HFti/EhHfTMUD256aiHgYuJrsWMJukobTpnydR9uTtu8KbJ7emjZ1NPBKSeuAr5GlZj7NYLYFgIi4N11uBC4j+/IdxM/aBmBDRFyfbl9CFux72pZBDu43AIvS0f/tgdcD3+lznTr1HeAt6fpbyHLXtfI3p6PlRwGP1H62lYEkAV8AbouIT+Y2DWp75kvaLV3fEXgZ2YGuHwGvTXdrbE+tna8F/iNSUrTfIuLsiNgvIhaS/W/8R0S8kQFsC4CknSXNrV0HjgfWMoCftYi4H1gv6eBU9FLgVnrdln4fXOjywMSJwC/I8qJ/3e/6TLLOFwP3AVvIvpHfTpbbvAq4M13unu4rshFBvwRuBpb0u/4NbTmG7OfhTcCa9HfiALfnMODnqT1rgb9N5QcAPwXuAv4NmJ3Kd0i370rbD+h3G5q061jgu4PcllTvG9PfLbX/9wH+rC0GVqXP2reAp/W6LZ5+wMysggY5LWNmZk04uJuZVZCDu5lZBTm4m5lVkIO7mVkFObibmVWQg7uZWQX9f393M2BaMxPdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And see the results\n",
    "def smooth(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "\n",
    "plt.plot(smooth(episode_durations, 10))\n",
    "plt.title('Episode durations per episode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With simulation visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
